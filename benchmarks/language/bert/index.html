
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../medical_imaging/3d-unet/">
      
      
        <link rel="next" href="../gpt-j/">
      
      
      <link rel="icon" href="../../../img/logo_v2.svg">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.24">
    
    
      
        <title>Bert-Large - MLPerf Inference Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6543a935.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#question-answering-using-bert-large" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="MLPerf Inference Documentation" class="md-header__button md-logo" aria-label="MLPerf Inference Documentation" data-md-component="logo">
      
  <img src="../../../img/logo_v2.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MLPerf Inference Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Bert-Large
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mlcommons/inference" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
    
  
  Inference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../install/" class="md-tabs__link">
          
  
    
  
  Install

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
    
  
  Benchmarks

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../submission/" class="md-tabs__link">
          
  
    
  
  Submission

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../changelog/" class="md-tabs__link">
          
  
    
  
  Release Notes

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="MLPerf Inference Documentation" class="md-nav__button md-logo" aria-label="MLPerf Inference Documentation" data-md-component="logo">
      
  <img src="../../../img/logo_v2.svg" alt="logo">

    </a>
    MLPerf Inference Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mlcommons/inference" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../.." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Inference
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Inference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../install/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Install
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Install
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../install/quick-start.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Benchmarks
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Benchmarks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Image Classification
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Image Classification
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../image_classification/resnet50/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ResNet50
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Text to Image
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Text to Image
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../text_to_image/sdxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Object Detection
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Object Detection
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../object_detection/retinanet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RetinaNet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Medical Imaging
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            Medical Imaging
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../medical_imaging/3d-unet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3d-unet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" checked>
        
          
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Language Processing
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            Language Processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Bert-Large
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Bert-Large
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get-validation-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Get Validation Dataset
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model" class="md-nav__link">
    <span class="md-ellipsis">
      Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#onnx" class="md-nav__link">
    <span class="md-ellipsis">
      Onnx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow" class="md-nav__link">
    <span class="md-ellipsis">
      Tensorflow
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#benchmark-implementations" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Implementations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Benchmark Implementations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mlperf-reference-implementation-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      MLPerf Reference Implementation in Python
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MLPerf Reference Implementation in Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-category" class="md-nav__link">
    <span class="md-ellipsis">
      Edge category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Edge category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#onnxruntime-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Onnxruntime framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Onnxruntime framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_1" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_2" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_1" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_3" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_1" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_4" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_1" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_5" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_2" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_2" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_6" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_2" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_7" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_2" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_8" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_3" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_3" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_9" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_3" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_10" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_3" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_11" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_4" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_4" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_12" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_4" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_13" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_4" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_14" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_5" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_5" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_15" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_5" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_16" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_5" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_17" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Tensorflow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensorflow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_2" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_6" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_6" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_18" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_6" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_19" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_6" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_20" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_2" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_7" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_7" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_21" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_7" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_22" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_7" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_23" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_2" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_8" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_8" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_24" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_8" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_25" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_8" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_26" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#onnxruntime-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      Onnxruntime framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Onnxruntime framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_3" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_9" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_9" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_27" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_28" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_9" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_29" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_3" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_10" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_10" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_30" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_31" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_10" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_32" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_3" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_11" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_11" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_33" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_2" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_34" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_11" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_35" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_4" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_12" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_12" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_36" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_3" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_37" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_12" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_38" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_4" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_13" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_13" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_39" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_4" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_40" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_13" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_41" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_4" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_14" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_14" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_42" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_5" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_43" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_14" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_44" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      Tensorflow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensorflow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_5" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_15" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_15" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_45" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_6" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_46" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_15" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_47" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_5" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_16" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_16" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_48" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_7" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_49" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_16" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_50" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_5" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_17" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_17" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_51" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_8" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_52" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_17" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_53" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_1" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#onnxruntime-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      Onnxruntime framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Onnxruntime framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_6" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_18" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_18" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_54" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_9" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_55" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_18" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_56" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_6" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_19" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_19" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_57" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_10" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_58" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_19" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_59" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_6" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_20" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_20" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_60" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_11" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_61" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_20" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_62" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_7" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_21" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_21" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_63" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_12" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_64" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_21" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_65" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_7" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_22" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_22" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_66" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_13" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_67" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_22" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_68" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_7" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_23" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_23" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_69" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_14" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_70" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_23" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_71" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      Tensorflow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensorflow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_8" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_24" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_24" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_72" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_15" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_73" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_24" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_74" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_8" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_25" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_25" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_75" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_16" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_76" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_25" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_77" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_8" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_26" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_26" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_78" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_17" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_79" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_26" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_80" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvidia-mlperf-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Nvidia MLPerf Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Nvidia MLPerf Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-category_1" class="md-nav__link">
    <span class="md-ellipsis">
      Edge category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Edge category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-framework" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-device_9" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_27" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_27" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_81" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_9" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_82" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_27" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_83" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_2" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-device_10" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_28" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_28" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_84" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_18" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_85" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_28" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_86" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_3" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-device_11" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_29" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_29" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_87" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_19" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_88" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_29" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_89" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intel-mlperf-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Intel MLPerf Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Intel MLPerf Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-category_2" class="md-nav__link">
    <span class="md-ellipsis">
      Edge category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Edge category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_3" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_9" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_30" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_30" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_90" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_10" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_91" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_30" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_92" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_4" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_4" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_10" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_31" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_31" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_93" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_20" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_94" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_31" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_95" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_5" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_5" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_11" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_32" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_32" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_96" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_21" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_97" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_32" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_98" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qualcomm-ai100-mlperf-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Qualcomm AI100 MLPerf Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Qualcomm AI100 MLPerf Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-category_3" class="md-nav__link">
    <span class="md-ellipsis">
      Edge category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Edge category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#glow-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Glow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Glow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qaic-device" class="md-nav__link">
    <span class="md-ellipsis">
      QAIC device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_33" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_33" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_99" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_11" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_100" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_33" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_101" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_6" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#glow-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      Glow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Glow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qaic-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      QAIC device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_34" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_34" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_102" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_22" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_103" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_34" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_104" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_7" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#glow-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      Glow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Glow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qaic-device_2" class="md-nav__link">
    <span class="md-ellipsis">
      QAIC device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_35" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_35" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_105" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_23" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_106" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_35" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_107" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt-j/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPT-J
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama2-70b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLAMA2-70B
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Recommendation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            Recommendation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../recommendation/dlrm-v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DLRM-v2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../submission/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Submission
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Submission
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../changelog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Release Notes
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Release Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../changelog/changelog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Changelog
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get-validation-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Get Validation Dataset
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model" class="md-nav__link">
    <span class="md-ellipsis">
      Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#onnx" class="md-nav__link">
    <span class="md-ellipsis">
      Onnx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow" class="md-nav__link">
    <span class="md-ellipsis">
      Tensorflow
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#benchmark-implementations" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Implementations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Benchmark Implementations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mlperf-reference-implementation-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      MLPerf Reference Implementation in Python
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MLPerf Reference Implementation in Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-category" class="md-nav__link">
    <span class="md-ellipsis">
      Edge category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Edge category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#onnxruntime-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Onnxruntime framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Onnxruntime framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_1" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_2" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_1" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_3" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_1" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_4" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_1" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_5" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_2" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_2" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_6" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_2" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_7" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_2" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_8" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_3" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_3" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_9" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_3" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_10" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_3" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_11" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_4" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_4" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_12" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_4" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_13" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_4" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_14" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_5" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_5" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_15" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_5" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_16" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_5" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_17" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Tensorflow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensorflow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_2" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_6" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_6" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_18" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_6" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_19" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_6" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_20" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_2" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_7" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_7" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_21" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_7" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_22" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_7" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_23" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_2" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_8" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_8" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_24" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_8" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_25" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_8" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_26" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#onnxruntime-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      Onnxruntime framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Onnxruntime framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_3" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_9" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_9" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_27" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_28" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_9" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_29" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_3" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_10" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_10" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_30" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_31" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_10" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_32" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_3" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_11" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_11" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_33" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_2" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_34" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_11" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_35" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_4" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_12" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_12" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_36" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_3" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_37" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_12" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_38" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_4" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_13" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_13" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_39" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_4" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_40" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_13" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_41" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_4" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_14" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_14" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_42" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_5" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_43" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_14" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_44" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      Tensorflow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensorflow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_5" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_15" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_15" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_45" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_6" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_46" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_15" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_47" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_5" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_16" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_16" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_48" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_7" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_49" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_16" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_50" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_5" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_17" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_17" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_51" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_8" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_52" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_17" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_53" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_1" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#onnxruntime-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      Onnxruntime framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Onnxruntime framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_6" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_18" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_18" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_54" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_9" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_55" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_18" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_56" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_6" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_19" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_19" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_57" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_10" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_58" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_19" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_59" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_6" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_20" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_20" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_60" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_11" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_61" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_20" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_62" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_7" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_21" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_21" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_63" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_12" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_64" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_21" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_65" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_7" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_22" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_22" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_66" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_13" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_67" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_22" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_68" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_7" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_23" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_23" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_69" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_14" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_70" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_23" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_71" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      Tensorflow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensorflow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_8" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_24" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_24" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_72" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_15" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_73" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_24" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_74" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device_8" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_25" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_25" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_75" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_16" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_76" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_25" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_77" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rocm-device_8" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_26" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_26" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_78" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_17" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_79" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_26" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_80" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvidia-mlperf-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Nvidia MLPerf Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Nvidia MLPerf Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-category_1" class="md-nav__link">
    <span class="md-ellipsis">
      Edge category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Edge category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-framework" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-device_9" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_27" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_27" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_81" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_9" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_82" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_27" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_83" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_2" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-device_10" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_28" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_28" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_84" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_18" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_85" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_28" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_86" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_3" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-device_11" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_29" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_29" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_87" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_19" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_88" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_29" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_89" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intel-mlperf-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Intel MLPerf Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Intel MLPerf Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-category_2" class="md-nav__link">
    <span class="md-ellipsis">
      Edge category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Edge category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_3" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_9" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_30" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_30" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_90" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_10" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_91" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_30" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_92" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_4" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_4" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_10" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_31" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_31" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_93" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_20" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_94" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_31" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_95" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_5" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-framework_5" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cpu-device_11" class="md-nav__link">
    <span class="md-ellipsis">
      CPU device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_32" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_32" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_96" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_21" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_97" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_32" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_98" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qualcomm-ai100-mlperf-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Qualcomm AI100 MLPerf Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Qualcomm AI100 MLPerf Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#edge-category_3" class="md-nav__link">
    <span class="md-ellipsis">
      Edge category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Edge category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#glow-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Glow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Glow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qaic-device" class="md-nav__link">
    <span class="md-ellipsis">
      QAIC device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_33" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_33" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_99" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#singlestream_11" class="md-nav__link">
    <span class="md-ellipsis">
      # SingleStream
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_100" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_33" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_101" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_6" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#glow-framework_1" class="md-nav__link">
    <span class="md-ellipsis">
      Glow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Glow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qaic-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      QAIC device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_34" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_34" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_102" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_22" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_103" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_34" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_104" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datacenter-category_7" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#glow-framework_2" class="md-nav__link">
    <span class="md-ellipsis">
      Glow framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Glow framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qaic-device_2" class="md-nav__link">
    <span class="md-ellipsis">
      QAIC device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-setup-command_35" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Setup Command
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_35" class="md-nav__link">
    <span class="md-ellipsis">
      # Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_105" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server_23" class="md-nav__link">
    <span class="md-ellipsis">
      # Server
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_106" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-scenarios_35" class="md-nav__link">
    <span class="md-ellipsis">
      # All Scenarios
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-options_107" class="md-nav__link">
    <span class="md-ellipsis">
      Run Options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="question-answering-using-bert-large">Question Answering using Bert-Large</h1>
<h2 id="dataset">Dataset</h2>
<p>The benchmark implementation run command will automatically download the validation and calibration datasets and do the necessary preprocessing. In case you want to download only the datasets, you can use the below commands.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:1"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">Validation</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>BERT validation run uses the SQuAD v1.1 dataset.</p>
<h3 id="get-validation-dataset">Get Validation Dataset</h3>
<div class="highlight"><pre><span></span><code>cm run script --tags=get,dataset,squad,validation -j
</code></pre></div>
</div>
</div>
</div>
<h2 id="model">Model</h2>
<p>The benchmark implementation run command will automatically download the required model and do the necessary conversions. In case you want to only download the official model, you can use the below commands.</p>
<p>Get the Official MLPerf Bert-Large Model</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:3"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Pytorch</label><label for="__tabbed_2_2">Onnx</label><label for="__tabbed_2_3">Tensorflow</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h3 id="pytorch">Pytorch</h3>
<div class="highlight"><pre><span></span><code>cm run script --tags=get,ml-model,bert-large,_pytorch -j
</code></pre></div>
</div>
<div class="tabbed-block">
<h3 id="onnx">Onnx</h3>
<div class="highlight"><pre><span></span><code>cm run script --tags=get,ml-model,bert-large,_onnx -j
</code></pre></div>
</div>
<div class="tabbed-block">
<h3 id="tensorflow">Tensorflow</h3>
<div class="highlight"><pre><span></span><code>cm run script --tags=get,ml-model,bert-large,_tensorflow -j
</code></pre></div>
</div>
</div>
</div>
<h2 id="benchmark-implementations">Benchmark Implementations</h2>
<div class="tabbed-set tabbed-alternate" data-tabs="3:4"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><input id="__tabbed_3_3" name="__tabbed_3" type="radio" /><input id="__tabbed_3_4" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">MLCommons-Python</label><label for="__tabbed_3_2">Nvidia</label><label for="__tabbed_3_3">Intel</label><label for="__tabbed_3_4">Qualcomm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h3 id="mlperf-reference-implementation-in-python">MLPerf Reference Implementation in Python</h3>
<p>BERT-99</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">edge</label><label for="__tabbed_4_2">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="edge-category">Edge category</h4>
<p>In the edge category, bert-99 has Offline, SingleStream scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:3"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><input id="__tabbed_5_3" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">Onnxruntime</label><label for="__tabbed_5_2">Pytorch</label><label for="__tabbed_5_3">Tensorflow</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="onnxruntime-framework">Onnxruntime framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="6:3"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><input id="__tabbed_6_2" name="__tabbed_6" type="radio" /><input id="__tabbed_6_3" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">CPU</label><label for="__tabbed_6_2">CUDA</label><label for="__tabbed_6_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device">CPU device</h6>
<h6 id="docker-setup-command">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="7:3"><input checked="checked" id="__tabbed_7_1" name="__tabbed_7" type="radio" /><input id="__tabbed_7_2" name="__tabbed_7" type="radio" /><input id="__tabbed_7_3" name="__tabbed_7" type="radio" /><div class="tabbed-labels"><label for="__tabbed_7_1">Offline</label><label for="__tabbed_7_2">SingleStream</label><label for="__tabbed_7_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_1">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_2">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device">CUDA device</h6>
<h6 id="docker-setup-command_1">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="8:3"><input checked="checked" id="__tabbed_8_1" name="__tabbed_8" type="radio" /><input id="__tabbed_8_2" name="__tabbed_8" type="radio" /><input id="__tabbed_8_3" name="__tabbed_8" type="radio" /><div class="tabbed-labels"><label for="__tabbed_8_1">Offline</label><label for="__tabbed_8_2">SingleStream</label><label for="__tabbed_8_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_1"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_3">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_1"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_4">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_1"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_5">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device">ROCm device</h6>
<h6 id="docker-setup-command_2">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="9:3"><input checked="checked" id="__tabbed_9_1" name="__tabbed_9" type="radio" /><input id="__tabbed_9_2" name="__tabbed_9" type="radio" /><input id="__tabbed_9_3" name="__tabbed_9" type="radio" /><div class="tabbed-labels"><label for="__tabbed_9_1">Offline</label><label for="__tabbed_9_2">SingleStream</label><label for="__tabbed_9_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_2"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_6">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_2"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_7">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_2"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_8">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h5 id="pytorch-framework">Pytorch framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="10:3"><input checked="checked" id="__tabbed_10_1" name="__tabbed_10" type="radio" /><input id="__tabbed_10_2" name="__tabbed_10" type="radio" /><input id="__tabbed_10_3" name="__tabbed_10" type="radio" /><div class="tabbed-labels"><label for="__tabbed_10_1">CPU</label><label for="__tabbed_10_2">CUDA</label><label for="__tabbed_10_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_1">CPU device</h6>
<h6 id="docker-setup-command_3">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="11:3"><input checked="checked" id="__tabbed_11_1" name="__tabbed_11" type="radio" /><input id="__tabbed_11_2" name="__tabbed_11" type="radio" /><input id="__tabbed_11_3" name="__tabbed_11" type="radio" /><div class="tabbed-labels"><label for="__tabbed_11_1">Offline</label><label for="__tabbed_11_2">SingleStream</label><label for="__tabbed_11_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_3"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_9">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_3"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_10">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_3"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_11">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device_1">CUDA device</h6>
<h6 id="docker-setup-command_4">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="12:3"><input checked="checked" id="__tabbed_12_1" name="__tabbed_12" type="radio" /><input id="__tabbed_12_2" name="__tabbed_12" type="radio" /><input id="__tabbed_12_3" name="__tabbed_12" type="radio" /><div class="tabbed-labels"><label for="__tabbed_12_1">Offline</label><label for="__tabbed_12_2">SingleStream</label><label for="__tabbed_12_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_4"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_12">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_4"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_13">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_4"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_14">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device_1">ROCm device</h6>
<h6 id="docker-setup-command_5">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="13:3"><input checked="checked" id="__tabbed_13_1" name="__tabbed_13" type="radio" /><input id="__tabbed_13_2" name="__tabbed_13" type="radio" /><input id="__tabbed_13_3" name="__tabbed_13" type="radio" /><div class="tabbed-labels"><label for="__tabbed_13_1">Offline</label><label for="__tabbed_13_2">SingleStream</label><label for="__tabbed_13_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_5"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_15">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_5"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_16">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_5"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_17">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h5 id="tensorflow-framework">Tensorflow framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="14:3"><input checked="checked" id="__tabbed_14_1" name="__tabbed_14" type="radio" /><input id="__tabbed_14_2" name="__tabbed_14" type="radio" /><input id="__tabbed_14_3" name="__tabbed_14" type="radio" /><div class="tabbed-labels"><label for="__tabbed_14_1">CPU</label><label for="__tabbed_14_2">CUDA</label><label for="__tabbed_14_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_2">CPU device</h6>
<h6 id="docker-setup-command_6">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="15:3"><input checked="checked" id="__tabbed_15_1" name="__tabbed_15" type="radio" /><input id="__tabbed_15_2" name="__tabbed_15" type="radio" /><input id="__tabbed_15_3" name="__tabbed_15" type="radio" /><div class="tabbed-labels"><label for="__tabbed_15_1">Offline</label><label for="__tabbed_15_2">SingleStream</label><label for="__tabbed_15_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_6"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_18">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_6"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_19">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_6"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_20">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device_2">CUDA device</h6>
<h6 id="docker-setup-command_7">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="16:3"><input checked="checked" id="__tabbed_16_1" name="__tabbed_16" type="radio" /><input id="__tabbed_16_2" name="__tabbed_16" type="radio" /><input id="__tabbed_16_3" name="__tabbed_16" type="radio" /><div class="tabbed-labels"><label for="__tabbed_16_1">Offline</label><label for="__tabbed_16_2">SingleStream</label><label for="__tabbed_16_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_7"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_21">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_7"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_22">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_7"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_23">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device_2">ROCm device</h6>
<h6 id="docker-setup-command_8">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="17:3"><input checked="checked" id="__tabbed_17_1" name="__tabbed_17" type="radio" /><input id="__tabbed_17_2" name="__tabbed_17" type="radio" /><input id="__tabbed_17_3" name="__tabbed_17" type="radio" /><div class="tabbed-labels"><label for="__tabbed_17_1">Offline</label><label for="__tabbed_17_2">SingleStream</label><label for="__tabbed_17_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_8"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_24">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_8"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_25">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_8"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_26">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h4 id="datacenter-category">Datacenter category</h4>
<p>In the datacenter category, bert-99 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="18:3"><input checked="checked" id="__tabbed_18_1" name="__tabbed_18" type="radio" /><input id="__tabbed_18_2" name="__tabbed_18" type="radio" /><input id="__tabbed_18_3" name="__tabbed_18" type="radio" /><div class="tabbed-labels"><label for="__tabbed_18_1">Onnxruntime</label><label for="__tabbed_18_2">Pytorch</label><label for="__tabbed_18_3">Tensorflow</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="onnxruntime-framework_1">Onnxruntime framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="19:3"><input checked="checked" id="__tabbed_19_1" name="__tabbed_19" type="radio" /><input id="__tabbed_19_2" name="__tabbed_19" type="radio" /><input id="__tabbed_19_3" name="__tabbed_19" type="radio" /><div class="tabbed-labels"><label for="__tabbed_19_1">CPU</label><label for="__tabbed_19_2">CUDA</label><label for="__tabbed_19_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_3">CPU device</h6>
<h6 id="docker-setup-command_9">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="20:3"><input checked="checked" id="__tabbed_20_1" name="__tabbed_20" type="radio" /><input id="__tabbed_20_2" name="__tabbed_20" type="radio" /><input id="__tabbed_20_3" name="__tabbed_20" type="radio" /><div class="tabbed-labels"><label for="__tabbed_20_1">Offline</label><label for="__tabbed_20_2">Server</label><label for="__tabbed_20_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_9"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_27">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_28">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_9"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_29">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device_3">CUDA device</h6>
<h6 id="docker-setup-command_10">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="21:3"><input checked="checked" id="__tabbed_21_1" name="__tabbed_21" type="radio" /><input id="__tabbed_21_2" name="__tabbed_21" type="radio" /><input id="__tabbed_21_3" name="__tabbed_21" type="radio" /><div class="tabbed-labels"><label for="__tabbed_21_1">Offline</label><label for="__tabbed_21_2">Server</label><label for="__tabbed_21_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_10"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_30">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_1"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_31">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_10"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_32">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device_3">ROCm device</h6>
<h6 id="docker-setup-command_11">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="22:3"><input checked="checked" id="__tabbed_22_1" name="__tabbed_22" type="radio" /><input id="__tabbed_22_2" name="__tabbed_22" type="radio" /><input id="__tabbed_22_3" name="__tabbed_22" type="radio" /><div class="tabbed-labels"><label for="__tabbed_22_1">Offline</label><label for="__tabbed_22_2">Server</label><label for="__tabbed_22_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_11"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_33">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_2"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_34">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_11"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_35">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h5 id="pytorch-framework_1">Pytorch framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="23:3"><input checked="checked" id="__tabbed_23_1" name="__tabbed_23" type="radio" /><input id="__tabbed_23_2" name="__tabbed_23" type="radio" /><input id="__tabbed_23_3" name="__tabbed_23" type="radio" /><div class="tabbed-labels"><label for="__tabbed_23_1">CPU</label><label for="__tabbed_23_2">CUDA</label><label for="__tabbed_23_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_4">CPU device</h6>
<h6 id="docker-setup-command_12">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="24:3"><input checked="checked" id="__tabbed_24_1" name="__tabbed_24" type="radio" /><input id="__tabbed_24_2" name="__tabbed_24" type="radio" /><input id="__tabbed_24_3" name="__tabbed_24" type="radio" /><div class="tabbed-labels"><label for="__tabbed_24_1">Offline</label><label for="__tabbed_24_2">Server</label><label for="__tabbed_24_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_12"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_36">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_3"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_37">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_12"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_38">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device_4">CUDA device</h6>
<h6 id="docker-setup-command_13">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="25:3"><input checked="checked" id="__tabbed_25_1" name="__tabbed_25" type="radio" /><input id="__tabbed_25_2" name="__tabbed_25" type="radio" /><input id="__tabbed_25_3" name="__tabbed_25" type="radio" /><div class="tabbed-labels"><label for="__tabbed_25_1">Offline</label><label for="__tabbed_25_2">Server</label><label for="__tabbed_25_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_13"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_39">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_4"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_40">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_13"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_41">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device_4">ROCm device</h6>
<h6 id="docker-setup-command_14">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="26:3"><input checked="checked" id="__tabbed_26_1" name="__tabbed_26" type="radio" /><input id="__tabbed_26_2" name="__tabbed_26" type="radio" /><input id="__tabbed_26_3" name="__tabbed_26" type="radio" /><div class="tabbed-labels"><label for="__tabbed_26_1">Offline</label><label for="__tabbed_26_2">Server</label><label for="__tabbed_26_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_14"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_42">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_5"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_43">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_14"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_44">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h5 id="tensorflow-framework_1">Tensorflow framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="27:3"><input checked="checked" id="__tabbed_27_1" name="__tabbed_27" type="radio" /><input id="__tabbed_27_2" name="__tabbed_27" type="radio" /><input id="__tabbed_27_3" name="__tabbed_27" type="radio" /><div class="tabbed-labels"><label for="__tabbed_27_1">CPU</label><label for="__tabbed_27_2">CUDA</label><label for="__tabbed_27_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_5">CPU device</h6>
<h6 id="docker-setup-command_15">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="28:3"><input checked="checked" id="__tabbed_28_1" name="__tabbed_28" type="radio" /><input id="__tabbed_28_2" name="__tabbed_28" type="radio" /><input id="__tabbed_28_3" name="__tabbed_28" type="radio" /><div class="tabbed-labels"><label for="__tabbed_28_1">Offline</label><label for="__tabbed_28_2">Server</label><label for="__tabbed_28_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_15"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_45">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_6"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_46">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_15"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_47">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device_5">CUDA device</h6>
<h6 id="docker-setup-command_16">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="29:3"><input checked="checked" id="__tabbed_29_1" name="__tabbed_29" type="radio" /><input id="__tabbed_29_2" name="__tabbed_29" type="radio" /><input id="__tabbed_29_3" name="__tabbed_29" type="radio" /><div class="tabbed-labels"><label for="__tabbed_29_1">Offline</label><label for="__tabbed_29_2">Server</label><label for="__tabbed_29_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_16"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_48">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_7"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_49">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_16"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_50">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device_5">ROCm device</h6>
<h6 id="docker-setup-command_17">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="30:3"><input checked="checked" id="__tabbed_30_1" name="__tabbed_30" type="radio" /><input id="__tabbed_30_2" name="__tabbed_30" type="radio" /><input id="__tabbed_30_3" name="__tabbed_30" type="radio" /><div class="tabbed-labels"><label for="__tabbed_30_1">Offline</label><label for="__tabbed_30_2">Server</label><label for="__tabbed_30_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_17"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_51">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_8"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_52">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_17"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_53">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p>BERT-99.9</p>
<div class="tabbed-set tabbed-alternate" data-tabs="31:1"><input checked="checked" id="__tabbed_31_1" name="__tabbed_31" type="radio" /><div class="tabbed-labels"><label for="__tabbed_31_1">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="datacenter-category_1">Datacenter category</h4>
<p>In the datacenter category, bert-99.9 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="32:3"><input checked="checked" id="__tabbed_32_1" name="__tabbed_32" type="radio" /><input id="__tabbed_32_2" name="__tabbed_32" type="radio" /><input id="__tabbed_32_3" name="__tabbed_32" type="radio" /><div class="tabbed-labels"><label for="__tabbed_32_1">Onnxruntime</label><label for="__tabbed_32_2">Pytorch</label><label for="__tabbed_32_3">Tensorflow</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="onnxruntime-framework_2">Onnxruntime framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="33:3"><input checked="checked" id="__tabbed_33_1" name="__tabbed_33" type="radio" /><input id="__tabbed_33_2" name="__tabbed_33" type="radio" /><input id="__tabbed_33_3" name="__tabbed_33" type="radio" /><div class="tabbed-labels"><label for="__tabbed_33_1">CPU</label><label for="__tabbed_33_2">CUDA</label><label for="__tabbed_33_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_6">CPU device</h6>
<h6 id="docker-setup-command_18">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="34:3"><input checked="checked" id="__tabbed_34_1" name="__tabbed_34" type="radio" /><input id="__tabbed_34_2" name="__tabbed_34" type="radio" /><input id="__tabbed_34_3" name="__tabbed_34" type="radio" /><div class="tabbed-labels"><label for="__tabbed_34_1">Offline</label><label for="__tabbed_34_2">Server</label><label for="__tabbed_34_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_18"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_54">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_9"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_55">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_18"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_56">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device_6">CUDA device</h6>
<h6 id="docker-setup-command_19">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="35:3"><input checked="checked" id="__tabbed_35_1" name="__tabbed_35" type="radio" /><input id="__tabbed_35_2" name="__tabbed_35" type="radio" /><input id="__tabbed_35_3" name="__tabbed_35" type="radio" /><div class="tabbed-labels"><label for="__tabbed_35_1">Offline</label><label for="__tabbed_35_2">Server</label><label for="__tabbed_35_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_19"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_57">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_10"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_58">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_19"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_59">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device_6">ROCm device</h6>
<h6 id="docker-setup-command_20">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="36:3"><input checked="checked" id="__tabbed_36_1" name="__tabbed_36" type="radio" /><input id="__tabbed_36_2" name="__tabbed_36" type="radio" /><input id="__tabbed_36_3" name="__tabbed_36" type="radio" /><div class="tabbed-labels"><label for="__tabbed_36_1">Offline</label><label for="__tabbed_36_2">Server</label><label for="__tabbed_36_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_20"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_60">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_11"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_61">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_20"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>onnxruntime<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_62">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h5 id="pytorch-framework_2">Pytorch framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="37:3"><input checked="checked" id="__tabbed_37_1" name="__tabbed_37" type="radio" /><input id="__tabbed_37_2" name="__tabbed_37" type="radio" /><input id="__tabbed_37_3" name="__tabbed_37" type="radio" /><div class="tabbed-labels"><label for="__tabbed_37_1">CPU</label><label for="__tabbed_37_2">CUDA</label><label for="__tabbed_37_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_7">CPU device</h6>
<h6 id="docker-setup-command_21">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="38:3"><input checked="checked" id="__tabbed_38_1" name="__tabbed_38" type="radio" /><input id="__tabbed_38_2" name="__tabbed_38" type="radio" /><input id="__tabbed_38_3" name="__tabbed_38" type="radio" /><div class="tabbed-labels"><label for="__tabbed_38_1">Offline</label><label for="__tabbed_38_2">Server</label><label for="__tabbed_38_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_21"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_63">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_12"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_64">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_21"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_65">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device_7">CUDA device</h6>
<h6 id="docker-setup-command_22">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="39:3"><input checked="checked" id="__tabbed_39_1" name="__tabbed_39" type="radio" /><input id="__tabbed_39_2" name="__tabbed_39" type="radio" /><input id="__tabbed_39_3" name="__tabbed_39" type="radio" /><div class="tabbed-labels"><label for="__tabbed_39_1">Offline</label><label for="__tabbed_39_2">Server</label><label for="__tabbed_39_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_22"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_66">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_13"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_67">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_22"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_68">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device_7">ROCm device</h6>
<h6 id="docker-setup-command_23">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="40:3"><input checked="checked" id="__tabbed_40_1" name="__tabbed_40" type="radio" /><input id="__tabbed_40_2" name="__tabbed_40" type="radio" /><input id="__tabbed_40_3" name="__tabbed_40" type="radio" /><div class="tabbed-labels"><label for="__tabbed_40_1">Offline</label><label for="__tabbed_40_2">Server</label><label for="__tabbed_40_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_23"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_69">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_14"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_70">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_23"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_71">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h5 id="tensorflow-framework_2">Tensorflow framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="41:3"><input checked="checked" id="__tabbed_41_1" name="__tabbed_41" type="radio" /><input id="__tabbed_41_2" name="__tabbed_41" type="radio" /><input id="__tabbed_41_3" name="__tabbed_41" type="radio" /><div class="tabbed-labels"><label for="__tabbed_41_1">CPU</label><label for="__tabbed_41_2">CUDA</label><label for="__tabbed_41_3">ROCm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_8">CPU device</h6>
<h6 id="docker-setup-command_24">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="42:3"><input checked="checked" id="__tabbed_42_1" name="__tabbed_42" type="radio" /><input id="__tabbed_42_2" name="__tabbed_42" type="radio" /><input id="__tabbed_42_3" name="__tabbed_42" type="radio" /><div class="tabbed-labels"><label for="__tabbed_42_1">Offline</label><label for="__tabbed_42_2">Server</label><label for="__tabbed_42_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_24"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_72">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_15"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_73">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_24"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_74">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="cuda-device_8">CUDA device</h6>
<h6 id="docker-setup-command_25">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="43:3"><input checked="checked" id="__tabbed_43_1" name="__tabbed_43" type="radio" /><input id="__tabbed_43_2" name="__tabbed_43" type="radio" /><input id="__tabbed_43_3" name="__tabbed_43" type="radio" /><div class="tabbed-labels"><label for="__tabbed_43_1">Offline</label><label for="__tabbed_43_2">Server</label><label for="__tabbed_43_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_25"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_75">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_16"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_76">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_25"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_77">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="rocm-device_8">ROCm device</h6>
<h6 id="docker-setup-command_26">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="44:3"><input checked="checked" id="__tabbed_44_1" name="__tabbed_44" type="radio" /><input id="__tabbed_44_2" name="__tabbed_44" type="radio" /><input id="__tabbed_44_3" name="__tabbed_44" type="radio" /><div class="tabbed-labels"><label for="__tabbed_44_1">Offline</label><label for="__tabbed_44_2">Server</label><label for="__tabbed_44_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_26"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_78">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_17"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_79">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_26"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorflow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_80">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h3 id="nvidia-mlperf-implementation">Nvidia MLPerf Implementation</h3>
<p>BERT-99</p>
<div class="tabbed-set tabbed-alternate" data-tabs="45:2"><input checked="checked" id="__tabbed_45_1" name="__tabbed_45" type="radio" /><input id="__tabbed_45_2" name="__tabbed_45" type="radio" /><div class="tabbed-labels"><label for="__tabbed_45_1">edge</label><label for="__tabbed_45_2">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="edge-category_1">Edge category</h4>
<p>In the edge category, bert-99 has Offline, SingleStream scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="46:1"><input checked="checked" id="__tabbed_46_1" name="__tabbed_46" type="radio" /><div class="tabbed-labels"><label for="__tabbed_46_1">TensorRT</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="tensorrt-framework">TensorRT framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="47:1"><input checked="checked" id="__tabbed_47_1" name="__tabbed_47" type="radio" /><div class="tabbed-labels"><label for="__tabbed_47_1">CUDA</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cuda-device_9">CUDA device</h6>
<h6 id="docker-setup-command_27">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="48:3"><input checked="checked" id="__tabbed_48_1" name="__tabbed_48" type="radio" /><input id="__tabbed_48_2" name="__tabbed_48" type="radio" /><input id="__tabbed_48_3" name="__tabbed_48" type="radio" /><div class="tabbed-labels"><label for="__tabbed_48_1">Offline</label><label for="__tabbed_48_2">SingleStream</label><label for="__tabbed_48_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_27"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_81">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_9"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_82">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_27"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_83">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h4 id="datacenter-category_2">Datacenter category</h4>
<p>In the datacenter category, bert-99 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="49:1"><input checked="checked" id="__tabbed_49_1" name="__tabbed_49" type="radio" /><div class="tabbed-labels"><label for="__tabbed_49_1">TensorRT</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="tensorrt-framework_1">TensorRT framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="50:1"><input checked="checked" id="__tabbed_50_1" name="__tabbed_50" type="radio" /><div class="tabbed-labels"><label for="__tabbed_50_1">CUDA</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cuda-device_10">CUDA device</h6>
<h6 id="docker-setup-command_28">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="51:3"><input checked="checked" id="__tabbed_51_1" name="__tabbed_51" type="radio" /><input id="__tabbed_51_2" name="__tabbed_51" type="radio" /><input id="__tabbed_51_3" name="__tabbed_51" type="radio" /><div class="tabbed-labels"><label for="__tabbed_51_1">Offline</label><label for="__tabbed_51_2">Server</label><label for="__tabbed_51_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_28"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_84">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_18"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_85">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_28"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_86">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p>BERT-99.9</p>
<div class="tabbed-set tabbed-alternate" data-tabs="52:1"><input checked="checked" id="__tabbed_52_1" name="__tabbed_52" type="radio" /><div class="tabbed-labels"><label for="__tabbed_52_1">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="datacenter-category_3">Datacenter category</h4>
<p>In the datacenter category, bert-99.9 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="53:1"><input checked="checked" id="__tabbed_53_1" name="__tabbed_53" type="radio" /><div class="tabbed-labels"><label for="__tabbed_53_1">TensorRT</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="tensorrt-framework_2">TensorRT framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="54:1"><input checked="checked" id="__tabbed_54_1" name="__tabbed_54" type="radio" /><div class="tabbed-labels"><label for="__tabbed_54_1">CUDA</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cuda-device_11">CUDA device</h6>
<h6 id="docker-setup-command_29">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="55:3"><input checked="checked" id="__tabbed_55_1" name="__tabbed_55" type="radio" /><input id="__tabbed_55_2" name="__tabbed_55" type="radio" /><input id="__tabbed_55_3" name="__tabbed_55" type="radio" /><div class="tabbed-labels"><label for="__tabbed_55_1">Offline</label><label for="__tabbed_55_2">Server</label><label for="__tabbed_55_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_29"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_87">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_19"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_88">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_29"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_89">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h3 id="intel-mlperf-implementation">Intel MLPerf Implementation</h3>
<p>BERT-99</p>
<div class="tabbed-set tabbed-alternate" data-tabs="56:2"><input checked="checked" id="__tabbed_56_1" name="__tabbed_56" type="radio" /><input id="__tabbed_56_2" name="__tabbed_56" type="radio" /><div class="tabbed-labels"><label for="__tabbed_56_1">edge</label><label for="__tabbed_56_2">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="edge-category_2">Edge category</h4>
<p>In the edge category, bert-99 has Offline, SingleStream scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="57:1"><input checked="checked" id="__tabbed_57_1" name="__tabbed_57" type="radio" /><div class="tabbed-labels"><label for="__tabbed_57_1">Pytorch</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="pytorch-framework_3">Pytorch framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="58:1"><input checked="checked" id="__tabbed_58_1" name="__tabbed_58" type="radio" /><div class="tabbed-labels"><label for="__tabbed_58_1">CPU</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_9">CPU device</h6>
<h6 id="docker-setup-command_30">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="59:3"><input checked="checked" id="__tabbed_59_1" name="__tabbed_59" type="radio" /><input id="__tabbed_59_2" name="__tabbed_59" type="radio" /><input id="__tabbed_59_3" name="__tabbed_59" type="radio" /><div class="tabbed-labels"><label for="__tabbed_59_1">Offline</label><label for="__tabbed_59_2">SingleStream</label><label for="__tabbed_59_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_30"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_90">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_10"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_91">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_30"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_92">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h4 id="datacenter-category_4">Datacenter category</h4>
<p>In the datacenter category, bert-99 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="60:1"><input checked="checked" id="__tabbed_60_1" name="__tabbed_60" type="radio" /><div class="tabbed-labels"><label for="__tabbed_60_1">Pytorch</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="pytorch-framework_4">Pytorch framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="61:1"><input checked="checked" id="__tabbed_61_1" name="__tabbed_61" type="radio" /><div class="tabbed-labels"><label for="__tabbed_61_1">CPU</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_10">CPU device</h6>
<h6 id="docker-setup-command_31">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="62:3"><input checked="checked" id="__tabbed_62_1" name="__tabbed_62" type="radio" /><input id="__tabbed_62_2" name="__tabbed_62" type="radio" /><input id="__tabbed_62_3" name="__tabbed_62" type="radio" /><div class="tabbed-labels"><label for="__tabbed_62_1">Offline</label><label for="__tabbed_62_2">Server</label><label for="__tabbed_62_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_31"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_93">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_20"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_94">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_31"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_95">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p>BERT-99.9</p>
<div class="tabbed-set tabbed-alternate" data-tabs="63:1"><input checked="checked" id="__tabbed_63_1" name="__tabbed_63" type="radio" /><div class="tabbed-labels"><label for="__tabbed_63_1">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="datacenter-category_5">Datacenter category</h4>
<p>In the datacenter category, bert-99.9 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="64:1"><input checked="checked" id="__tabbed_64_1" name="__tabbed_64" type="radio" /><div class="tabbed-labels"><label for="__tabbed_64_1">Pytorch</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="pytorch-framework_5">Pytorch framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="65:1"><input checked="checked" id="__tabbed_65_1" name="__tabbed_65" type="radio" /><div class="tabbed-labels"><label for="__tabbed_65_1">CPU</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="cpu-device_11">CPU device</h6>
<h6 id="docker-setup-command_32">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="66:3"><input checked="checked" id="__tabbed_66_1" name="__tabbed_66" type="radio" /><input id="__tabbed_66_2" name="__tabbed_66" type="radio" /><input id="__tabbed_66_3" name="__tabbed_66" type="radio" /><div class="tabbed-labels"><label for="__tabbed_66_1">Offline</label><label for="__tabbed_66_2">Server</label><label for="__tabbed_66_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_32"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_96">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_21"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_97">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_32"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>intel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_98">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h3 id="qualcomm-ai100-mlperf-implementation">Qualcomm AI100 MLPerf Implementation</h3>
<p>BERT-99</p>
<div class="tabbed-set tabbed-alternate" data-tabs="67:2"><input checked="checked" id="__tabbed_67_1" name="__tabbed_67" type="radio" /><input id="__tabbed_67_2" name="__tabbed_67" type="radio" /><div class="tabbed-labels"><label for="__tabbed_67_1">edge</label><label for="__tabbed_67_2">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="edge-category_3">Edge category</h4>
<p>In the edge category, bert-99 has Offline, SingleStream scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="68:1"><input checked="checked" id="__tabbed_68_1" name="__tabbed_68" type="radio" /><div class="tabbed-labels"><label for="__tabbed_68_1">Glow</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="glow-framework">Glow framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="69:1"><input checked="checked" id="__tabbed_69_1" name="__tabbed_69" type="radio" /><div class="tabbed-labels"><label for="__tabbed_69_1">QAIC</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="qaic-device">QAIC device</h6>
<h6 id="docker-setup-command_33">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="70:3"><input checked="checked" id="__tabbed_70_1" name="__tabbed_70" type="radio" /><input id="__tabbed_70_2" name="__tabbed_70" type="radio" /><input id="__tabbed_70_3" name="__tabbed_70" type="radio" /><div class="tabbed-labels"><label for="__tabbed_70_1">Offline</label><label for="__tabbed_70_2">SingleStream</label><label for="__tabbed_70_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_33"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_99">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="singlestream_11"># SingleStream</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>SingleStream<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_100">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_33"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>edge<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_101">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h4 id="datacenter-category_6">Datacenter category</h4>
<p>In the datacenter category, bert-99 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="71:1"><input checked="checked" id="__tabbed_71_1" name="__tabbed_71" type="radio" /><div class="tabbed-labels"><label for="__tabbed_71_1">Glow</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="glow-framework_1">Glow framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="72:1"><input checked="checked" id="__tabbed_72_1" name="__tabbed_72" type="radio" /><div class="tabbed-labels"><label for="__tabbed_72_1">QAIC</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="qaic-device_1">QAIC device</h6>
<h6 id="docker-setup-command_34">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="73:3"><input checked="checked" id="__tabbed_73_1" name="__tabbed_73" type="radio" /><input id="__tabbed_73_2" name="__tabbed_73" type="radio" /><input id="__tabbed_73_3" name="__tabbed_73" type="radio" /><div class="tabbed-labels"><label for="__tabbed_73_1">Offline</label><label for="__tabbed_73_2">Server</label><label for="__tabbed_73_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_34"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_102">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_22"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_103">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_34"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_104">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p>BERT-99.9</p>
<div class="tabbed-set tabbed-alternate" data-tabs="74:1"><input checked="checked" id="__tabbed_74_1" name="__tabbed_74" type="radio" /><div class="tabbed-labels"><label for="__tabbed_74_1">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="datacenter-category_7">Datacenter category</h4>
<p>In the datacenter category, bert-99.9 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="75:1"><input checked="checked" id="__tabbed_75_1" name="__tabbed_75" type="radio" /><div class="tabbed-labels"><label for="__tabbed_75_1">Glow</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="glow-framework_2">Glow framework</h5>
<div class="tabbed-set tabbed-alternate" data-tabs="76:1"><input checked="checked" id="__tabbed_76_1" name="__tabbed_76" type="radio" /><div class="tabbed-labels"><label for="__tabbed_76_1">QAIC</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="qaic-device_2">QAIC device</h6>
<h6 id="docker-setup-command_35">Docker Setup Command</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_full<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--test_query_count<span class="o">=</span><span class="m">100</span>
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for each scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo &lt;Custom CM repo URL&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--docker_os=ubuntu</code>: ubuntu and rhel are supported. </li>
<li><code>--docker_os_version=20.04</code>: [20.04, 22.04] are supported for Ubuntu and [8, 9] for RHEL
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="77:3"><input checked="checked" id="__tabbed_77_1" name="__tabbed_77" type="radio" /><input id="__tabbed_77_2" name="__tabbed_77" type="radio" /><input id="__tabbed_77_3" name="__tabbed_77" type="radio" /><div class="tabbed-labels"><label for="__tabbed_77_1">Offline</label><label for="__tabbed_77_2">Server</label><label for="__tabbed_77_3">All Scenarios</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_35"># Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_105">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="server_23"># Server</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Server<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_106">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
<div class="tabbed-block">
<h6 id="all-scenarios_35"># All Scenarios</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_all-scenarios<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>bert-99.9<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>qualcomm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>glow<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--execution-mode<span class="o">=</span>valid<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>qaic<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<h6 id="run-options_107">Run Options</h6>
<ul>
<li>
<p>Use <code>--division=closed</code> to do a closed division submission which includes compliance runs</p>
</li>
<li>
<p>Use <code>--rerun</code> to do a rerun even when a valid run exists</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.tabs.link", "content.code.copy", "navigation.expand", "navigation.sections", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "toc.follow"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.081f42fc.min.js"></script>
      
    
  </body>
</html>