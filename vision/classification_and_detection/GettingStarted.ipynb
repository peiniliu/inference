{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A short tutorial how to use the mlperf inference reference benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrapped all inference models into a single benchmark app. The benchmark app will read the propper dataset, preprocesses it and interface with the backend. Traffic is generated by loadgen, which depending on the desired mode drives the desired traffic to the benchmark app. \n",
    "\n",
    "To run this notebook, pick a directory and clone the mlperf source tree:\n",
    "```\n",
    "cd /tmp\n",
    "git clone --recurse-submodules https://github.com/mlcommons/inference.git --depth 1\n",
    "cd inference/vision/classification_and_detection\n",
    "jupyter notebook \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pybind11=2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running develop\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running egg_info\n",
      "writing mlperf_loadgen.egg-info/PKG-INFO\n",
      "writing dependency_links to mlperf_loadgen.egg-info/dependency_links.txt\n",
      "writing top-level names to mlperf_loadgen.egg-info/top_level.txt\n",
      "reading manifest file 'mlperf_loadgen.egg-info/SOURCES.txt'\n",
      "writing manifest file 'mlperf_loadgen.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "building 'mlperf_loadgen' extension\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c bindings/python_api.cc -o build/temp.linux-x86_64-cpython-38/bindings/python_api.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:16\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/internals.h:82:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kint PyThread_create_key()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   82 |     decltype(\u001b[01;35m\u001b[KPyThread_create_key()\u001b[m\u001b[K) tstate = 0; // Usually an int but a long on Cygwin64 with Python 3.x\n",
      "      |              \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:100:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  100 | Py_DEPRECATED(3.7) PyAPI_FUNC(int) \u001b[01;36m\u001b[KPyThread_create_key\u001b[m\u001b[K(void);\n",
      "      |                                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:16\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/internals.h:82:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kint PyThread_create_key()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   82 |     decltype(\u001b[01;35m\u001b[KPyThread_create_key()\u001b[m\u001b[K) tstate = 0; // Usually an int but a long on Cygwin64 with Python 3.x\n",
      "      |              \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:100:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  100 | Py_DEPRECATED(3.7) PyAPI_FUNC(int) \u001b[01;36m\u001b[KPyThread_create_key\u001b[m\u001b[K(void);\n",
      "      |                                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:16\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/internals.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpybind11::detail::internals& pybind11::detail::get_internals()\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/internals.h:167:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kint PyThread_create_key()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  167 |         internals_ptr->tstate = \u001b[01;35m\u001b[KPyThread_create_key()\u001b[m\u001b[K;\n",
      "      |                                 \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:100:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  100 | Py_DEPRECATED(3.7) PyAPI_FUNC(int) \u001b[01;36m\u001b[KPyThread_create_key\u001b[m\u001b[K(void);\n",
      "      |                                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:16\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/internals.h:168:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kint PyThread_set_key_value(int, void*)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  168 |         \u001b[01;35m\u001b[KPyThread_set_key_value(internals_ptr->tstate, tstate)\u001b[m\u001b[K;\n",
      "      |         \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:102:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  102 | Py_DEPRECATED(3.7) PyAPI_FUNC(int) \u001b[01;36m\u001b[KPyThread_set_key_value\u001b[m\u001b[K(int key,\n",
      "      |                                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:\u001b[m\u001b[K In constructor ‘\u001b[01m\u001b[Kpybind11::gil_scoped_acquire::gil_scoped_acquire()\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:1713:58:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid* PyThread_get_key_value(int)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1713 |         tstate = (PyThreadState *) \u001b[01;35m\u001b[KPyThread_get_key_value(internals.tstate)\u001b[m\u001b[K;\n",
      "      |                                    \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:104:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  104 | Py_DEPRECATED(3.7) PyAPI_FUNC(void *) \u001b[01;36m\u001b[KPyThread_get_key_value\u001b[m\u001b[K(int key);\n",
      "      |                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:1725:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kint PyThread_set_key_value(int, void*)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1725 |             \u001b[01;35m\u001b[KPyThread_set_key_value(internals.tstate, tstate)\u001b[m\u001b[K;\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:102:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  102 | Py_DEPRECATED(3.7) PyAPI_FUNC(int) \u001b[01;36m\u001b[KPyThread_set_key_value\u001b[m\u001b[K(int key,\n",
      "      |                                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid pybind11::gil_scoped_acquire::dec_ref()\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:1764:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid PyThread_delete_key_value(int)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1764 |             \u001b[01;35m\u001b[KPyThread_delete_key_value(detail::get_internals().tstate)\u001b[m\u001b[K;\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:105:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  105 | Py_DEPRECATED(3.7) PyAPI_FUNC(void) \u001b[01;36m\u001b[KPyThread_delete_key_value\u001b[m\u001b[K(int key);\n",
      "      |                                     \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:\u001b[m\u001b[K In constructor ‘\u001b[01m\u001b[Kpybind11::gil_scoped_release::gil_scoped_release(bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:1792:39:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kint PyThread_set_key_value(int, void*)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1792 |                 \u001b[01;35m\u001b[KPyThread_set_key_value(key, nullptr)\u001b[m\u001b[K;\n",
      "      |                 \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:102:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  102 | Py_DEPRECATED(3.7) PyAPI_FUNC(int) \u001b[01;36m\u001b[KPyThread_set_key_value\u001b[m\u001b[K(int key,\n",
      "      |                                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:\u001b[m\u001b[K In destructor ‘\u001b[01m\u001b[Kpybind11::gil_scoped_release::~gil_scoped_release()\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:1805:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kint PyThread_set_key_value(int, void*)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1805 |             \u001b[01;35m\u001b[KPyThread_set_key_value(key, tstate)\u001b[m\u001b[K;\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pystate.h:10\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/genobject.h:11\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/Python.h:121\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/detail/common.h:111\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pytypes.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/cast.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/attr.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/pybind11.h:43\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pybind11/functional.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kbindings/python_api.cc:27\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8/pythread.h:102:36:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  102 | Py_DEPRECATED(3.7) PyAPI_FUNC(int) \u001b[01;36m\u001b[KPyThread_set_key_value\u001b[m\u001b[K(int key,\n",
      "      |                                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c early_stopping.cc -o build/temp.linux-x86_64-cpython-38/early_stopping.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c generated/version_generated.cc -o build/temp.linux-x86_64-cpython-38/generated/version_generated.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c issue_query_controller.cc -o build/temp.linux-x86_64-cpython-38/issue_query_controller.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c loadgen.cc -o build/temp.linux-x86_64-cpython-38/loadgen.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c logging.cc -o build/temp.linux-x86_64-cpython-38/logging.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c results.cc -o build/temp.linux-x86_64-cpython-38/results.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c test_settings_internal.cc -o build/temp.linux-x86_64-cpython-38/test_settings_internal.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c utils.cc -o build/temp.linux-x86_64-cpython-38/utils.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -std=c++14 -fPIC -DMAJOR_VERSION=3 -DMINOR_VERSION=0 -I. -I../third_party/pybind/include -I/home/pliu/opt/miniconda3/envs/mlperf/include/python3.8 -c version.cc -o build/temp.linux-x86_64-cpython-38/version.o\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand-line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "creating build/lib.linux-x86_64-cpython-38\n",
      "g++ -pthread -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -Wl,--sysroot=/ -pthread -shared -B /home/pliu/opt/miniconda3/envs/mlperf/compiler_compat -L/home/pliu/opt/miniconda3/envs/mlperf/lib -Wl,-rpath=/home/pliu/opt/miniconda3/envs/mlperf/lib -Wl,--no-as-needed -Wl,--sysroot=/ -std=c++14 build/temp.linux-x86_64-cpython-38/bindings/python_api.o build/temp.linux-x86_64-cpython-38/early_stopping.o build/temp.linux-x86_64-cpython-38/generated/version_generated.o build/temp.linux-x86_64-cpython-38/issue_query_controller.o build/temp.linux-x86_64-cpython-38/loadgen.o build/temp.linux-x86_64-cpython-38/logging.o build/temp.linux-x86_64-cpython-38/results.o build/temp.linux-x86_64-cpython-38/test_settings_internal.o build/temp.linux-x86_64-cpython-38/utils.o build/temp.linux-x86_64-cpython-38/version.o -o build/lib.linux-x86_64-cpython-38/mlperf_loadgen.cpython-38-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-cpython-38/mlperf_loadgen.cpython-38-x86_64-linux-gnu.so -> \n",
      "Creating /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/mlperf-loadgen.egg-link (link to .)\n",
      "Adding mlperf-loadgen 3.0 to easy-install.pth file\n",
      "\n",
      "Installed /home/pliu/opt/inference/loadgen\n",
      "Processing dependencies for mlperf-loadgen==3.0\n",
      "Finished processing dependencies for mlperf-loadgen==3.0\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/setuptools/installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "  warnings.warn(\n",
      "running develop\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running create_version\n",
      "running build\n",
      "running build_py\n",
      "copying python/version.py -> build/lib/python\n",
      "running egg_info\n",
      "writing mlperf_inference.egg-info/PKG-INFO\n",
      "writing dependency_links to mlperf_inference.egg-info/dependency_links.txt\n",
      "writing requirements to mlperf_inference.egg-info/requires.txt\n",
      "writing top-level names to mlperf_inference.egg-info/top_level.txt\n",
      "reading manifest file 'mlperf_inference.egg-info/SOURCES.txt'\n",
      "writing manifest file 'mlperf_inference.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "Creating /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/mlperf-inference.egg-link (link to .)\n",
      "mlperf-inference 0.1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/pliu/opt/inference/vision/classification_and_detection\n",
      "Processing dependencies for mlperf-inference==0.1.0\n",
      "Searching for onnx>=1.5\n",
      "Reading https://pypi.org/simple/onnx/\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning:  is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "Downloading https://files.pythonhosted.org/packages/15/51/a3cf9d237c81d26abc1c78e8355b1a777fbafcb0c35c07f086a8f4721c67/onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=e980706de4dc94ffafc57e4ae7e7f4117dbd4c377882637c28a261a6aed38246\n",
      "Best match: onnx 1.13.1\n",
      "Processing onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Adding onnx 1.13.1 to easy-install.pth file\n",
      "Installing backend-test-tools script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing check-model script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing check-node script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "\n",
      "Installed /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/onnx-1.13.1-py3.8-linux-x86_64.egg\n",
      "Searching for protobuf<4,>=3.20.2\n",
      "Reading https://pypi.org/simple/protobuf/\n",
      "Downloading https://files.pythonhosted.org/packages/da/e4/4d62585593e9f962cb02614534f62f930de6a80a0a3784282094a01919b2/protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl#sha256=44246bab5dd4b7fbd3c0c80b6f16686808fab0e4aca819ade6e8d294a29c7050\n",
      "Best match: protobuf 3.20.3\n",
      "Processing protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n",
      "Installing protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl to /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Adding protobuf 3.20.3 to easy-install.pth file\n",
      "\n",
      "Installed /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/protobuf-3.20.3-py3.8-linux-x86_64.egg\n",
      "Searching for opencv-python-headless==4.7.0.72\n",
      "Best match: opencv-python-headless 4.7.0.72\n",
      "Processing opencv_python_headless-4.7.0.72-py3.8-linux-x86_64.egg\n",
      "opencv-python-headless 4.7.0.72 is already the active version in easy-install.pth\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/opencv_python_headless-4.7.0.72-py3.8-linux-x86_64.egg\n",
      "Searching for mlperf-loadgen==3.0\n",
      "Best match: mlperf-loadgen 3.0\n",
      "mlperf-loadgen 3.0 is already the active version in easy-install.pth\n",
      "\n",
      "Using /home/pliu/opt/inference/loadgen\n",
      "Searching for pycocotools==2.0.6\n",
      "Best match: pycocotools 2.0.6\n",
      "Adding pycocotools 2.0.6 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for Cython==0.29.33\n",
      "Best match: Cython 0.29.33\n",
      "Adding Cython 0.29.33 to easy-install.pth file\n",
      "Installing cygdb script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing cython script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing cythonize script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for pybind11==2.2.0\n",
      "Best match: pybind11 2.2.0\n",
      "Adding pybind11 2.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for numpy==1.24.2\n",
      "Best match: numpy 1.24.2\n",
      "Adding numpy 1.24.2 to easy-install.pth file\n",
      "Installing f2py script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing f2py3 script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing f2py3.8 script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for matplotlib==3.7.1\n",
      "Best match: matplotlib 3.7.1\n",
      "Adding matplotlib 3.7.1 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for typing-extensions==4.5.0\n",
      "Best match: typing-extensions 4.5.0\n",
      "Adding typing-extensions 4.5.0 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for importlib-resources==5.12.0\n",
      "Best match: importlib-resources 5.12.0\n",
      "Adding importlib-resources 5.12.0 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for pyparsing==3.0.9\n",
      "Best match: pyparsing 3.0.9\n",
      "Adding pyparsing 3.0.9 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for Pillow==9.4.0\n",
      "Best match: Pillow 9.4.0\n",
      "Adding Pillow 9.4.0 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for packaging==23.0\n",
      "Best match: packaging 23.0\n",
      "Adding packaging 23.0 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for kiwisolver==1.4.4\n",
      "Best match: kiwisolver 1.4.4\n",
      "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for fonttools==4.39.3\n",
      "Best match: fonttools 4.39.3\n",
      "Adding fonttools 4.39.3 to easy-install.pth file\n",
      "Installing fonttools script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing pyftmerge script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing pyftsubset script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "Installing ttx script to /home/pliu/opt/miniconda3/envs/mlperf/bin\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for cycler==0.11.0\n",
      "Best match: cycler 0.11.0\n",
      "Adding cycler 0.11.0 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for contourpy==1.0.7\n",
      "Best match: contourpy 1.0.7\n",
      "Adding contourpy 1.0.7 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for zipp==3.15.0\n",
      "Best match: zipp 3.15.0\n",
      "Adding zipp 3.15.0 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages\n",
      "Finished processing dependencies for mlperf-inference==0.1.0\n"
     ]
    }
   ],
   "source": [
    "!cd ../../loadgen; CFLAGS=\"-std=c++14\" python setup.py develop; cd {root}\n",
    "!python setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark app uses a shell script to simplify command line options and the user can pick backend, model and device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ./run_local.sh tf|onnxruntime|pytorch|tflite|tvm-onnx|tvm-pytorch [resnet50|mobilenet|ssd-mobilenet|ssd-resnet34|retinanet] [cpu|gpu]\n"
     ]
    }
   ],
   "source": [
    "!./run_local.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the benchmark, device on model and dataset and set the environment variable ```MODEL_DIR``` and ```DATA_DIR```. \n",
    "\n",
    "For this tutorial we use onnxruntime (tensorflow and pytorch will work as well), mobilenet and a fake imagetnet dataset with a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime in /opt/anaconda3/lib/python3.7/site-packages (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime pycocotools opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - download the model. You find the links to the models [here](https://github.com/mlperf/inference/tree/master/v0.5/classification_and_detection#supported-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -q https://zenodo.org/record/3157894/files/mobilenet_v1_1.0_224.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - download the dataset. For this tutorial we create a small, fake dataset that pretends to be imagenet.\n",
    "Normally you'd need to download imagenet2012/valiation for image classification or coco2017/valiation for object detections.\n",
    "\n",
    "Links and instructions how to download the datasets can be found in the [README](https://github.com/mlperf/inference/tree/master/v0.5/classification_and_detection#datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tools/make_fake_imagenet.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - tell the benchmark where to find model and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MODEL_DIR'] = root\n",
    "os.environ['DATA_DIR'] = os.path.join(root, \"fake_imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mlperf submission number of queries, time, latencies and percentiles are given and we default to those settings. But for this tuturial we pass in some extra options to make things go quicker.\n",
    "run_local.sh will look for the evironment variable EXTRA_OPS and add this to the arguments. You can also add additional arguments in the command line.\n",
    "The options below will limit the time that the benchmarks run to 10 seconds and adds accuracy reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['EXTRA_OPS'] =\"--time 10 --max-latency 0.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - run the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pliu/opt/inference/vision/classification_and_detection/model\n"
     ]
    }
   ],
   "source": [
    "!echo \"$MODEL_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pliu/opt/open-mmlab/data/imagenet\n"
     ]
    }
   ],
   "source": [
    "!echo \"$DATA_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 python/main.py --profile mobilenet-onnxruntime --mlperf_conf ../../mlperf.conf --model \"/home/pliu/opt/inference/vision/classification_and_detection/model/mobilenet_v1_1.0_224.onnx\" --dataset-path /home/pliu/opt/open-mmlab/data/imagenet --output \"/home/pliu/opt/inference/vision/classification_and_detection/output/onnxruntime-cpu/mobilenet\" --accuracy\n",
      "INFO:main:Namespace(accuracy=True, audit_conf='audit.config', backend='onnxruntime', cache=0, cache_dir=None, count=None, data_format=None, dataset='imagenet_mobilenet', dataset_list=None, dataset_path='/home/pliu/opt/open-mmlab/data/imagenet', debug=False, find_peak_performance=False, inputs=None, max_batchsize=32, max_latency=None, mlperf_conf='../../mlperf.conf', model='/home/pliu/opt/inference/vision/classification_and_detection/model/mobilenet_v1_1.0_224.onnx', model_name='mobilenet', output='/home/pliu/opt/inference/vision/classification_and_detection/output/onnxruntime-cpu/mobilenet', outputs=['MobilenetV1/Predictions/Reshape_1:0'], performance_sample_count=None, preprocessed_dir=None, profile='mobilenet-onnxruntime', qps=None, samples_per_query=8, scenario='SingleStream', threads=144, time=None, use_preprocessed_dataset=False, user_conf='user.conf')\n",
      "INFO:imagenet:Preprocessing 50000 images using 144 threads\n",
      "INFO:imagenet:loaded 50000 images, cache=0, already_preprocessed=False, took=1.4sec\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:54: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "2023-03-31 10:14:04.522911722 [W:onnxruntime:, graph.cc:1231 Graph] Initializer reshape__254__255 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522933025 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Predictions/Reshape/shape:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522939639 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522946040 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522951853 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522957443 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522963447 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522968792 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522974416 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522979745 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522985658 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522991102 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.522996853 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523002534 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523008644 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523014050 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523020549 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Logits/Conv2d_1c_1x1/weights/read/_136__cf__136:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523025863 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Logits/Conv2d_1c_1x1/biases/read/_135__cf__135:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523031689 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_pointwise/weights/read/_134__cf__134:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523037201 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_variance/read/_128__cf__128:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523043079 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_mean/read/_127__cf__127:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523048413 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/read/_126__cf__126:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523054125 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/read/_125__cf__125:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523061987 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_pointwise/weights/read/_124__cf__124:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523067878 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_variance/read/_118__cf__118:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523073182 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_mean/read/_117__cf__117:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523078860 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/read/_116__cf__116:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523084181 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/read/_115__cf__115:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523089933 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_pointwise/weights/read/_114__cf__114:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523095603 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_variance/read/_108__cf__108:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523101244 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_mean/read/_107__cf__107:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523106614 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/read/_106__cf__106:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523112228 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/read/_105__cf__105:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523117851 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_pointwise/weights/read/_104__cf__104:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523123467 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_variance/read/_98__cf__98:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523128916 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_mean/read/_97__cf__97:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523134611 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/read/_96__cf__96:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523140062 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/read/_95__cf__95:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523145624 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_pointwise/weights/read/_94__cf__94:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523150929 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_variance/read/_88__cf__88:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523156475 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_mean/read/_87__cf__87:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523161773 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/read/_86__cf__86:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523167343 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/read/_85__cf__85:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523172637 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_pointwise/weights/read/_84__cf__84:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523178302 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_variance/read/_78__cf__78:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.523183585 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_mean/read/_77__cf__77:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524850896 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/read/_76__cf__76:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524857527 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/read/_75__cf__75:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524865914 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_pointwise/weights/read/_74__cf__74:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524872310 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_variance/read/_68__cf__68:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524878896 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_mean/read/_67__cf__67:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524885232 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/read/_66__cf__66:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524891786 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/read/_65__cf__65:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524898421 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_pointwise/weights/read/_64__cf__64:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524905027 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_variance/read/_58__cf__58:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524911436 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_mean/read/_57__cf__57:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524917852 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/read/_56__cf__56:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524924189 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/read/_55__cf__55:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524930912 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_pointwise/weights/read/_54__cf__54:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524938056 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_variance/read/_48__cf__48:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524944517 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_mean/read/_47__cf__47:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524950650 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/read/_46__cf__46:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524957122 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/read/_45__cf__45:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524963546 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_pointwise/weights/read/_44__cf__44:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524970148 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_variance/read/_38__cf__38:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524976400 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_mean/read/_37__cf__37:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524982632 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/read/_36__cf__36:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524987852 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/read/_35__cf__35:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524993526 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_pointwise/weights/read/_34__cf__34:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.524998765 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_variance/read/_28__cf__28:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525004276 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_mean/read/_27__cf__27:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525009685 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/read/_26__cf__26:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525014992 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/read/_25__cf__25:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525020541 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_pointwise/weights/read/_24__cf__24:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525026020 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_variance/read/_18__cf__18:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525031353 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_mean/read/_17__cf__17:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525036886 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/read/_16__cf__16:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525042381 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/read/_15__cf__15:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525049326 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_pointwise/weights/read/_14__cf__14:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525054749 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_variance/read/_8__cf__8:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525060208 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_mean/read/_7__cf__7:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525065471 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/read/_6__cf__6:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525070885 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/read/_5__cf__5:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525076326 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_0/weights/read/_4__cf__4:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525082097 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__223:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525087442 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__222:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525092832 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__221:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.525098142 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__220:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526677623 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__219:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526684283 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__218:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526690784 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__217:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526697058 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__216:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526703573 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__215:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526709850 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__214:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526716250 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__213:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526722418 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__212:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:14:04.526728819 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__211:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "INFO:main:starting TestScenario.SingleStream\n",
      "TestScenario.SingleStream qps=6913.34, mean=0.0140, time=7.232, acc=71.678%, queries=50000, tiles=50.0:0.0140,80.0:0.0144,90.0:0.0147,95.0:0.0150,99.0:0.0161,99.9:0.0194\n"
     ]
    }
   ],
   "source": [
    "!./run_local.sh onnxruntime mobilenet cpu --accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line ```Accuracy``` reports accuracy or mAP together with some latencies in various percentiles so you can insight how this run was. Above accuracy was 87.5%.\n",
    "\n",
    "The line ```TestScenario.SingleStream-1.0``` reports the latency and qps seen during the benchmark.\n",
    "\n",
    "For submission the official logging is found in [mlperf_log_summary.txt](mlperf_log_summary.txt) and [mlperf_log_detail.txt](mlperf_log_detail.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read over the mlperf inference rules guide you'll find multiple scenarios to be run for the inference benchmarks:\n",
    "\n",
    "|scenario|description|\n",
    "|:---|:---|\n",
    "|SingleStream|The LoadGen sends the next query as soon as the SUT completes the previous one.|\n",
    "|MultiStream|The LoadGen sends the next query as soon as the SUT completes the previous one. Each query contains multiple samples.|\n",
    "|Server|The LoadGen sends new queries to the SUT according to a Poisson distribution. Overtime queries must not exceed 2x the latency bound.|\n",
    "|Offline|The LoadGen sends all queries to the SUT at one time.|\n",
    "\n",
    "We can run those scenario using the ```--scenario``` option in the command line, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 python/main.py --profile mobilenet-onnxruntime --mlperf_conf ../../mlperf.conf --model \"/home/pliu/opt/inference/vision/classification_and_detection/model/mobilenet_v1_1.0_224.onnx\" --dataset-path /home/pliu/opt/open-mmlab/data/imagenet --output \"/home/pliu/opt/inference/vision/classification_and_detection/output/onnxruntime-cpu/mobilenet\" --scenario Offline --accuracy\n",
      "INFO:main:Namespace(accuracy=True, audit_conf='audit.config', backend='onnxruntime', cache=0, cache_dir=None, count=None, data_format=None, dataset='imagenet_mobilenet', dataset_list=None, dataset_path='/home/pliu/opt/open-mmlab/data/imagenet', debug=False, find_peak_performance=False, inputs=None, max_batchsize=32, max_latency=None, mlperf_conf='../../mlperf.conf', model='/home/pliu/opt/inference/vision/classification_and_detection/model/mobilenet_v1_1.0_224.onnx', model_name='mobilenet', output='/home/pliu/opt/inference/vision/classification_and_detection/output/onnxruntime-cpu/mobilenet', outputs=['MobilenetV1/Predictions/Reshape_1:0'], performance_sample_count=None, preprocessed_dir=None, profile='mobilenet-onnxruntime', qps=None, samples_per_query=8, scenario='Offline', threads=144, time=None, use_preprocessed_dataset=False, user_conf='user.conf')\n",
      "INFO:imagenet:Preprocessing 50000 images using 144 threads\n",
      "INFO:imagenet:loaded 50000 images, cache=0, already_preprocessed=False, took=1.4sec\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:54: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "2023-03-31 10:28:03.918671986 [W:onnxruntime:, graph.cc:1231 Graph] Initializer reshape__254__255 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918702445 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Predictions/Reshape/shape:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918713932 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918722709 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918731916 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918740153 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918748800 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918757047 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918765617 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918773685 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918782360 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918790396 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918799230 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918807713 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918816233 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918824351 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918833215 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Logits/Conv2d_1c_1x1/weights/read/_136__cf__136:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918841318 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Logits/Conv2d_1c_1x1/biases/read/_135__cf__135:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918850066 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_pointwise/weights/read/_134__cf__134:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918858268 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_variance/read/_128__cf__128:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918867204 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_mean/read/_127__cf__127:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918875275 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/read/_126__cf__126:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918885014 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/read/_125__cf__125:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918896084 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_pointwise/weights/read/_124__cf__124:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918905200 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_variance/read/_118__cf__118:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918913358 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_mean/read/_117__cf__117:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918922160 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/read/_116__cf__116:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918930345 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/read/_115__cf__115:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918939324 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_pointwise/weights/read/_114__cf__114:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918947885 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_variance/read/_108__cf__108:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918956498 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_mean/read/_107__cf__107:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918964544 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/read/_106__cf__106:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918973322 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/read/_105__cf__105:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918981634 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_pointwise/weights/read/_104__cf__104:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918990227 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_variance/read/_98__cf__98:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.918998302 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_mean/read/_97__cf__97:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919006958 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/read/_96__cf__96:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919015034 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/read/_95__cf__95:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919023830 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_pointwise/weights/read/_94__cf__94:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919031931 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_variance/read/_88__cf__88:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919040502 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_mean/read/_87__cf__87:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919048451 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/read/_86__cf__86:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919057029 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/read/_85__cf__85:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919065251 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_pointwise/weights/read/_84__cf__84:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919073746 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_variance/read/_78__cf__78:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.919081794 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_mean/read/_77__cf__77:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920620555 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/read/_76__cf__76:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920630942 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/read/_75__cf__75:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920643460 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_pointwise/weights/read/_74__cf__74:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920653926 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_variance/read/_68__cf__68:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920665087 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_mean/read/_67__cf__67:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920675712 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/read/_66__cf__66:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920686625 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/read/_65__cf__65:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920697752 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_pointwise/weights/read/_64__cf__64:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920707138 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_variance/read/_58__cf__58:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920715341 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_mean/read/_57__cf__57:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920723795 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/read/_56__cf__56:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920731747 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/read/_55__cf__55:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920740384 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_pointwise/weights/read/_54__cf__54:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920749282 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_variance/read/_48__cf__48:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920757708 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_mean/read/_47__cf__47:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920765747 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/read/_46__cf__46:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920774136 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/read/_45__cf__45:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920781619 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_pointwise/weights/read/_44__cf__44:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920789807 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_variance/read/_38__cf__38:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920797856 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_mean/read/_37__cf__37:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920805984 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/read/_36__cf__36:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920814128 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/read/_35__cf__35:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920822804 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_pointwise/weights/read/_34__cf__34:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920830761 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_variance/read/_28__cf__28:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920839078 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_mean/read/_27__cf__27:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920846997 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/read/_26__cf__26:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920855522 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/read/_25__cf__25:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920863759 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_pointwise/weights/read/_24__cf__24:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920872027 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_variance/read/_18__cf__18:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920880073 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_mean/read/_17__cf__17:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920888408 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/read/_16__cf__16:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920896546 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/read/_15__cf__15:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920906365 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_pointwise/weights/read/_14__cf__14:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920914468 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_variance/read/_8__cf__8:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920922711 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_mean/read/_7__cf__7:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920930727 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/read/_6__cf__6:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920939002 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/read/_5__cf__5:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920947504 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_0/weights/read/_4__cf__4:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920956156 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__223:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920964322 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__222:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920972587 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__221:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920980480 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__220:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920989672 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__219:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.920997560 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__218:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.921006254 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__217:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.921014140 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__216:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.922643999 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__215:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.922654088 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__214:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.922665239 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__213:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.922675727 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__212:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 10:28:03.922686559 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__211:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "INFO:main:starting TestScenario.Offline\n",
      "TestScenario.Offline qps=1855.14, mean=0.7095, time=0.862, acc=71.678%, queries=1600, tiles=50.0:0.7261,80.0:0.7521,90.0:0.7834,95.0:0.8032,99.0:0.8638,99.9:0.9910\n"
     ]
    }
   ],
   "source": [
    "!./run_local.sh onnxruntime mobilenet cpu --scenario Offline --accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional logfiles\n",
    "\n",
    "We log some additional information [here](output/mobilenet-onnxruntime-cpu/results.json) which can be used to plot graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the hood\n",
    "\n",
    "In case you wonder what the run_local.sh does, it only assembles the command line for the python based benchmark app. Command ine options for the app are documented [here](https://github.com/mlperf/inference/blob/master/cloud/image_classification)\n",
    "\n",
    "Calling\n",
    "```\n",
    "!bash -x ./run_local.sh onnxruntime mobilenet cpu  --accuracy \n",
    "```\n",
    "will results in the following command line:\n",
    "```\n",
    "python python/main.py --profile mobilenet-onnxruntime --model /tmp/inference/cloud/image_classification/mobilenet_v1_1.0_224.onnx --dataset-path /tmp/inference/cloud/image_classification/fake_imagenet --output /tmp/inference/cloud/image_classification/output/mobilenet-onnxruntime-cpu/results.json --queries-offline 20 --time 10 --max-latency 0.2 --accuracy\n",
    "```\n",
    "During testing you can change some of the options to have faster test cycles but for final submission use the defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using docker\n",
    "\n",
    "Instead of run_local.sh you can use run_and_time.sh which does have the same options but instead of running local will run the benchmark under docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  18.54MB\n",
      "Step 1/15 : FROM ubuntu:16.04\n",
      " ---> bd3d4369aebc\n",
      "Step 2/15 : ENV PYTHON_VERSION=3.7\n",
      " ---> Using cache\n",
      " ---> e25f214201a2\n",
      "Step 3/15 : ENV LANG C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 12986ee696e1\n",
      "Step 4/15 : ENV LC_ALL C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 1460535b24e1\n",
      "Step 5/15 : ENV PATH /opt/anaconda3/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> f4c922578fdf\n",
      "Step 6/15 : WORKDIR /root\n",
      " ---> Using cache\n",
      " ---> fb0ec9a436a5\n",
      "Step 7/15 : ENV HOME /root\n",
      " ---> Using cache\n",
      " ---> edeb7c15ebfb\n",
      "Step 8/15 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 42da1a4fa3fd\n",
      "Step 9/15 : RUN apt-get install -y --no-install-recommends       git       build-essential       software-properties-common       ca-certificates       wget       curl       htop       zip       unzip\n",
      " ---> Using cache\n",
      " ---> a1de66a3c7bd\n",
      "Step 10/15 : RUN cd /opt &&     wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-4.6.14-Linux-x86_64.sh -O miniconda.sh &&     /bin/bash ./miniconda.sh -b -p /opt/anaconda3 &&     rm miniconda.sh &&     /opt/anaconda3/bin/conda clean -tipsy &&     ln -s /opt/anaconda3/etc/profile.d/conda.sh /etc/profile.d/conda.sh &&     echo \". /opt/anaconda3/etc/profile.d/conda.sh\" >> ~/.bashrc &&     echo \"conda activate base\" >> ~/.bashrc &&     conda config --set always_yes yes --set changeps1 no\n",
      " ---> Using cache\n",
      " ---> b3a1fa068421\n",
      "Step 11/15 : RUN conda install pytorch-cpu torchvision-cpu -c pytorch\n",
      " ---> Using cache\n",
      " ---> 0f7c294fe4c8\n",
      "Step 12/15 : RUN pip install future pillow onnx opencv-python-headless tensorflow onnxruntime\n",
      " ---> Using cache\n",
      " ---> 160977b84ece\n",
      "Step 13/15 : RUN pip install Cython && pip install pycocotools\n",
      " ---> Using cache\n",
      " ---> ffc479fc7d11\n",
      "Step 14/15 : RUN cd /tmp &&     git clone https://github.com/mlperf/inference &&     cd inference/loadgen &&     pip install pybind11 &&     CFLAGS=\"-std=c++14\" python setup.py install &&     rm -rf mlperf\n",
      " ---> Using cache\n",
      " ---> 20eb0ce678b0\n",
      "Step 15/15 : ENTRYPOINT [\"/bin/bash\"]\n",
      " ---> Using cache\n",
      " ---> 9440a8884457\n",
      "Successfully built 9440a8884457\n",
      "Successfully tagged mlperf-infer-imgclassify-cpu:latest\n",
      "Clearing caches.\n",
      "3\n",
      "STARTING RUN AT 2019-07-23 04:09:29 PM\n",
      "INFO:main:Namespace(accuracy=False, backend='onnxruntime', cache=0, count=None, data_format=None, dataset='imagenet_mobilenet', dataset_list=None, dataset_path='/home/gs/inference/v0.5/classification_and_detection/fake_imagenet', inputs=None, max_batchsize=32, max_latency=[0.2], model='/home/gs/inference/v0.5/classification_and_detection/mobilenet_v1_1.0_224.onnx', output='/output/results.json', outputs=['MobilenetV1/Predictions/Reshape_1:0'], profile='mobilenet-onnxruntime', qps=10, queries_multi=24576, queries_offline=20, queries_single=1024, scenario=[TestScenario.SingleStream], threads=8, time=10)\n",
      "INFO:imagenet:loaded 8 images, cache=0, took=0.3sec\n",
      "INFO:main:starting TestScenario.SingleStream\n",
      "TestScenario.SingleStream qps=37.18, mean=0.0268, time=10.09, queries=375, tiles=50.0:0.0261,80.0:0.0262,90.0:0.0266,95.0:0.0271,99.0:0.0385,99.9:0.0823\n",
      "ENDING RUN AT 2019-07-23 04:09:45 PM\n"
     ]
    }
   ],
   "source": [
    "!./run_and_time.sh onnxruntime mobilenet cpu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for offical submision\n",
    "\n",
    "TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:main:Namespace(accuracy=True, audit_conf='audit.config', backend='onnxruntime', cache=0, cache_dir=None, count=None, data_format=None, dataset='imagenet_mobilenet', dataset_list=None, dataset_path='/home/pliu/opt/open-mmlab/data/imagenet', debug=False, find_peak_performance=False, inputs=None, max_batchsize=32, max_latency=None, mlperf_conf='../../mlperf.conf', model='/home/pliu/opt/inference/vision/classification_and_detection/model/mobilenet_v1_1.0_224.onnx', model_name='mobilenet', output='/tmp/inference/cloud/image_classification/output/mobilenet-onnxruntime-cpu/results.json', outputs=['MobilenetV1/Predictions/Reshape_1:0'], performance_sample_count=None, preprocessed_dir=None, profile='mobilenet-onnxruntime', qps=None, samples_per_query=8, scenario='Offline', threads=144, time=None, use_preprocessed_dataset=False, user_conf='user.conf')\n",
      "INFO:imagenet:Preprocessing 50000 images using 144 threads\n",
      "INFO:imagenet:loaded 50000 images, cache=0, already_preprocessed=False, took=1.4sec\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:54: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "2023-03-31 12:14:58.316317740 [W:onnxruntime:, graph.cc:1231 Graph] Initializer reshape__254__255 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316344014 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Predictions/Reshape/shape:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316353204 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316361854 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316370258 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316378223 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316386491 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316394367 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316402626 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316410415 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316418668 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316426572 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316434938 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316443148 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316451349 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316459239 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_bn_offset:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316468433 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Logits/Conv2d_1c_1x1/weights/read/_136__cf__136:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316476369 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Logits/Conv2d_1c_1x1/biases/read/_135__cf__135:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316484827 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_pointwise/weights/read/_134__cf__134:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316495507 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_variance/read/_128__cf__128:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316504404 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_mean/read/_127__cf__127:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316512234 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/read/_126__cf__126:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316520388 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/read/_125__cf__125:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316528458 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_pointwise/weights/read/_124__cf__124:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316536890 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_variance/read/_118__cf__118:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316544842 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_mean/read/_117__cf__117:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316553497 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/read/_116__cf__116:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316561514 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/read/_115__cf__115:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316570083 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_pointwise/weights/read/_114__cf__114:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316578360 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_variance/read/_108__cf__108:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316586388 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_mean/read/_107__cf__107:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316594149 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/read/_106__cf__106:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316602239 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/read/_105__cf__105:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316610287 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_pointwise/weights/read/_104__cf__104:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316618491 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_variance/read/_98__cf__98:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316626433 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_mean/read/_97__cf__97:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316634586 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/read/_96__cf__96:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316642464 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/read/_95__cf__95:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316650959 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_pointwise/weights/read/_94__cf__94:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316658957 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_variance/read/_88__cf__88:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316667011 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_mean/read/_87__cf__87:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316674932 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/read/_86__cf__86:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316682986 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/read/_85__cf__85:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.316690992 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_pointwise/weights/read/_84__cf__84:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318212736 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_variance/read/_78__cf__78:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318223068 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_mean/read/_77__cf__77:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318233894 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/read/_76__cf__76:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318244564 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/read/_75__cf__75:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318256552 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_pointwise/weights/read/_74__cf__74:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318266697 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_variance/read/_68__cf__68:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318277471 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_mean/read/_67__cf__67:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318287759 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/read/_66__cf__66:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318298212 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/read/_65__cf__65:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318308534 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_pointwise/weights/read/_64__cf__64:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318316832 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_variance/read/_58__cf__58:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318324742 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_mean/read/_57__cf__57:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318332872 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/read/_56__cf__56:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318340706 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/read/_55__cf__55:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318349079 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_pointwise/weights/read/_54__cf__54:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318357699 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_variance/read/_48__cf__48:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318365793 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_mean/read/_47__cf__47:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318372950 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/read/_46__cf__46:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318380908 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/read/_45__cf__45:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318388913 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_pointwise/weights/read/_44__cf__44:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318397369 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_variance/read/_38__cf__38:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318405243 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_mean/read/_37__cf__37:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318413231 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/read/_36__cf__36:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318421104 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/read/_35__cf__35:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318429501 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_pointwise/weights/read/_34__cf__34:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318437296 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_variance/read/_28__cf__28:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318445278 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_mean/read/_27__cf__27:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318453130 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/read/_26__cf__26:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318461264 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/read/_25__cf__25:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318469368 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_pointwise/weights/read/_24__cf__24:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318478642 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_variance/read/_18__cf__18:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318486538 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_mean/read/_17__cf__17:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318494854 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/read/_16__cf__16:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318502881 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/read/_15__cf__15:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318511259 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_pointwise/weights/read/_14__cf__14:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318519084 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_variance/read/_8__cf__8:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318527234 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_mean/read/_7__cf__7:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318535043 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/read/_6__cf__6:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318543086 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/read/_5__cf__5:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318551196 [W:onnxruntime:, graph.cc:1231 Graph] Initializer MobilenetV1/Conv2d_0/weights/read/_4__cf__4:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318559480 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__223:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318567325 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__222:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318575261 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__221:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318583008 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__220:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318590930 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__219:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.318598706 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__218:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.320249053 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__217:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.320259609 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__216:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.320270404 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__215:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.320280407 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__214:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.320290592 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__213:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.320300563 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__212:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2023-03-31 12:14:58.320310812 [W:onnxruntime:, graph.cc:1231 Graph] Initializer Const__211:0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "INFO:main:starting TestScenario.Offline\n",
      "TestScenario.Offline qps=1847.13, mean=0.7169, time=0.866, acc=71.678%, queries=1600, tiles=50.0:0.7289,80.0:0.7572,90.0:0.7793,95.0:0.8131,99.0:0.9614,99.9:1.0531\n"
     ]
    }
   ],
   "source": [
    "!python python/main.py \\\n",
    "    --profile mobilenet-onnxruntime \\\n",
    "    --model /home/pliu/opt/inference/vision/classification_and_detection/model/mobilenet_v1_1.0_224.onnx \\\n",
    "    --dataset-path /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --output /tmp/inference/cloud/image_classification/output/mobilenet-onnxruntime-cpu/results.json \\\n",
    "    --scenario Offline --accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h]\n",
      "               [--dataset {imagenet,imagenet_mobilenet,imagenet_pytorch,coco-300,coco-300-pt,openimages-300-retinanet,openimages-800-retinanet,openimages-1200-retinanet,openimages-800-retinanet-onnx,coco-1200,coco-1200-onnx,coco-1200-pt,coco-1200-tf}]\n",
      "               --dataset-path DATASET_PATH [--dataset-list DATASET_LIST]\n",
      "               [--data-format {NCHW,NHWC}]\n",
      "               [--profile {defaults,resnet50-tf,resnet50-pytorch,resnet50-onnxruntime,mobilenet-tf,mobilenet-onnxruntime,ssd-mobilenet-tf,ssd-mobilenet-pytorch,ssd-mobilenet-onnxruntime,ssd-resnet34-tf,ssd-resnet34-pytorch,ssd-resnet34-onnxruntime,ssd-resnet34-onnxruntime-tf,retinanet-pytorch,retinanet-onnxruntime}]\n",
      "               [--scenario SCENARIO] [--max-batchsize MAX_BATCHSIZE] --model\n",
      "               MODEL [--output OUTPUT] [--inputs INPUTS] [--outputs OUTPUTS]\n",
      "               [--backend BACKEND] [--model-name MODEL_NAME]\n",
      "               [--threads THREADS] [--qps QPS] [--cache CACHE]\n",
      "               [--cache_dir CACHE_DIR] [--preprocessed_dir PREPROCESSED_DIR]\n",
      "               [--use_preprocessed_dataset] [--accuracy]\n",
      "               [--find-peak-performance] [--debug] [--mlperf_conf MLPERF_CONF]\n",
      "               [--user_conf USER_CONF] [--audit_conf AUDIT_CONF] [--time TIME]\n",
      "               [--count COUNT]\n",
      "               [--performance-sample-count PERFORMANCE_SAMPLE_COUNT]\n",
      "               [--max-latency MAX_LATENCY]\n",
      "               [--samples-per-query SAMPLES_PER_QUERY]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --dataset {imagenet,imagenet_mobilenet,imagenet_pytorch,coco-300,coco-300-pt,openimages-300-retinanet,openimages-800-retinanet,openimages-1200-retinanet,openimages-800-retinanet-onnx,coco-1200,coco-1200-onnx,coco-1200-pt,coco-1200-tf}\n",
      "                        dataset\n",
      "  --dataset-path DATASET_PATH\n",
      "                        path to the dataset\n",
      "  --dataset-list DATASET_LIST\n",
      "                        path to the dataset list\n",
      "  --data-format {NCHW,NHWC}\n",
      "                        data format\n",
      "  --profile {defaults,resnet50-tf,resnet50-pytorch,resnet50-onnxruntime,mobilenet-tf,mobilenet-onnxruntime,ssd-mobilenet-tf,ssd-mobilenet-pytorch,ssd-mobilenet-onnxruntime,ssd-resnet34-tf,ssd-resnet34-pytorch,ssd-resnet34-onnxruntime,ssd-resnet34-onnxruntime-tf,retinanet-pytorch,retinanet-onnxruntime}\n",
      "                        standard profiles\n",
      "  --scenario SCENARIO   mlperf benchmark scenario, one of ['SingleStream',\n",
      "                        'MultiStream', 'Server', 'Offline']\n",
      "  --max-batchsize MAX_BATCHSIZE\n",
      "                        max batch size in a single inference\n",
      "  --model MODEL         model file\n",
      "  --output OUTPUT       test results\n",
      "  --inputs INPUTS       model inputs\n",
      "  --outputs OUTPUTS     model outputs\n",
      "  --backend BACKEND     runtime to use\n",
      "  --model-name MODEL_NAME\n",
      "                        name of the mlperf model, ie. resnet50\n",
      "  --threads THREADS     threads\n",
      "  --qps QPS             target qps\n",
      "  --cache CACHE         use cache\n",
      "  --cache_dir CACHE_DIR\n",
      "                        dir path for caching\n",
      "  --preprocessed_dir PREPROCESSED_DIR\n",
      "                        dir path for storing preprocessed images (overrides\n",
      "                        cache_dir)\n",
      "  --use_preprocessed_dataset\n",
      "                        use preprocessed dataset instead of the original\n",
      "  --accuracy            enable accuracy pass\n",
      "  --find-peak-performance\n",
      "                        enable finding peak performance pass\n",
      "  --debug               debug, turn traces on\n",
      "  --mlperf_conf MLPERF_CONF\n",
      "                        mlperf rules config\n",
      "  --user_conf USER_CONF\n",
      "                        user config for user LoadGen settings such as target\n",
      "                        QPS\n",
      "  --audit_conf AUDIT_CONF\n",
      "                        config for LoadGen audit settings\n",
      "  --time TIME           time to scan in seconds\n",
      "  --count COUNT         dataset items to use\n",
      "  --performance-sample-count PERFORMANCE_SAMPLE_COUNT\n",
      "                        performance sample count\n",
      "  --max-latency MAX_LATENCY\n",
      "                        mlperf max latency in pct tile\n",
      "  --samples-per-query SAMPLES_PER_QUERY\n",
      "                        mlperf multi-stream samples per query\n"
     ]
    }
   ],
   "source": [
    "!python python/main.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "load checkpoint from local path: /home/pliu/opt/open-mmlab/mmclassification/models/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth\n",
      "/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000001.JPEG\n",
      "65\n",
      "{\n",
      "    \"pred_label\": 65,\n",
      "    \"pred_score\": 0.6649361252784729,\n",
      "    \"pred_class\": \"sea snake\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python python/image_demo.py \\\n",
    "/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000001.JPEG \\\n",
    "/home/pliu/opt/open-mmlab/mmclassification/configs/resnet/resnet50_8xb32_in1k.py \\\n",
    "/home/pliu/opt/open-mmlab/mmclassification/models/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:main:Namespace(accuracy=False, audit_conf='audit.config', backend='pytorch-local', cache=0, cache_dir=None, count=50000, data_format=None, dataset='imagenet_img', dataset_list=None, dataset_path='/home/pliu/opt/open-mmlab/data/imagenet', debug=False, find_peak_performance=False, inputs=['/home/pliu/opt/open-mmlab/mmclassification/configs/resnet/resnet50_8xb32_in1k.py'], max_batchsize=32, max_latency=None, mlperf_conf='../../mlperf.conf', model='/home/pliu/opt/open-mmlab/mmclassification/models/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth', model_name='resnet50', output='/home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchlocal-cpu-server-baseline', outputs=None, performance_sample_count=None, preprocessed_dir='/home/pliu/opt/open-mmlab/data/imagenet', profile='resnet50-pytorchlocal', qps=200, samples_per_query=8, scenario='Server', threads=72, time=None, use_preprocessed_dataset=True, user_conf='user.conf')\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "load checkpoint from local path: /home/pliu/opt/open-mmlab/mmclassification/models/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth\n"
     ]
    }
   ],
   "source": [
    "!python python/main.py \\\n",
    "    --profile resnet50-pytorchlocal \\\n",
    "    --inputs /home/pliu/opt/open-mmlab/mmclassification/configs/resnet/resnet50_8xb32_in1k.py \\\n",
    "    --model /home/pliu/opt/open-mmlab/mmclassification/models/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth \\\n",
    "    --dataset-path /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --use_preprocessed_data \\\n",
    "    --preprocessed_dir /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --output /home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchlocal-cpu-server-baseline \\\n",
    "    --scenario Server --count 50000 --qps 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:main:Namespace(accuracy=True, audit_conf='audit.config', backend='pytorch-server', cache=0, cache_dir=None, count=1000, data_format=None, dataset='imagenet_img', dataset_list=None, dataset_path='/home/pliu/opt/open-mmlab/data/imagenet', debug=False, find_peak_performance=False, inputs=['/home/pliu/opt/open-mmlab/mmclassification/configs/resnet/resnet50_8xb32_in1k.py'], max_batchsize=32, max_latency=None, mlperf_conf='../../mlperf.conf', model='resnet50_8xb32_in1k', model_name='resnet50', output='/home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchserver-cpu-server-baseline', outputs=None, performance_sample_count=None, preprocessed_dir='/home/pliu/opt/open-mmlab/data/imagenet', profile='resnet50-pytorchserver', qps=1, samples_per_query=8, scenario='Server', threads=72, time=None, use_preprocessed_dataset=True, user_conf='user.conf')\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000835.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000154.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000554.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000416.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000871.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000418.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000672.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000276.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000133.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000560.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000609.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000638.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000243.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000527.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000330.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000338.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000585.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000626.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000157.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000905.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000831.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000868.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000707.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000196.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000089.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000820.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000475.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000227.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000927.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000788.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000210.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000232.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000128.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000724.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000851.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000625.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000402.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000249.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000686.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000780.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000783.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000523.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000214.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000897.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000631.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000383.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000690.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000757.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000617.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000602.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000528.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000777.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000410.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000370.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000945.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000898.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000655.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000773.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000241.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000442.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000215.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000459.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000006.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000005.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000350.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000052.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000491.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000726.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000590.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000308.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000721.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000663.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000396.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000237.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000109.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000840.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000483.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000176.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000643.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000244.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000758.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000930.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000811.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000603.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000079.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000524.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000185.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000150.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000826.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000106.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000263.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000464.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000668.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000951.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000148.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000652.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000321.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000950.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000599.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000009.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000064.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000500.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000616.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000085.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000791.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000694.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000124.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000165.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000111.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000155.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000987.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000001.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000387.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000357.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000451.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000457.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000092.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000815.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000839.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000943.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000620.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000779.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000796.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000490.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000360.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000856.JPEG'], 'pred_label'\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000025.JPEG'], 'pred_label'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python python/main.py \\\n",
    "    --profile resnet50-pytorchserver \\\n",
    "    --inputs /home/pliu/opt/open-mmlab/mmclassification/configs/resnet/resnet50_8xb32_in1k.py \\\n",
    "    --model resnet50_8xb32_in1k \\\n",
    "    --dataset-path /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --use_preprocessed_data \\\n",
    "    --preprocessed_dir /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --output /home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchserver-cpu-server-baseline \\\n",
    "    --scenario Server --accuracy --count 1000 --qps 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:main:Namespace(accuracy=True, audit_conf='audit.config', backend='pytorch-server', cache=0, cache_dir=None, count=50, data_format=None, dataset='imagenet_img', dataset_list=None, dataset_path='/home/pliu/opt/open-mmlab/data/imagenet', debug=False, find_peak_performance=False, inputs=['127.0.0.1:8080'], max_batchsize=32, max_latency=None, mlperf_conf='../../mlperf.conf', model='resnet18_8xb32_in1k', model_name='resnet50', output='/home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchserver-cpu-server-baseline', outputs=None, performance_sample_count=None, preprocessed_dir='/home/pliu/opt/open-mmlab/data/imagenet', profile='resnet50-pytorchserver', qps=None, samples_per_query=8, scenario='Server', threads=72, time=None, use_preprocessed_dataset=True, user_conf='user.conf')\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "['http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k']\n",
      "TestScenario.Server qps=0.43, mean=34.6969, time=116.877, acc=64.000%, queries=50, tiles=50.0:36.0099,80.0:51.3212,90.0:57.4448,95.0:62.0215,99.0:62.8917,99.9:62.9522\n"
     ]
    }
   ],
   "source": [
    "!python python/main.py \\\n",
    "    --profile resnet50-pytorchserver \\\n",
    "    --inputs 127.0.0.1:8080 \\\n",
    "    --model resnet18_8xb32_in1k \\\n",
    "    --dataset-path /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --use_preprocessed_data \\\n",
    "    --preprocessed_dir /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --output /home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchserver-cpu-server-baseline \\\n",
    "    --scenario Server --accuracy --count 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:main:Namespace(accuracy=True, audit_conf='audit.config', backend='pytorch-server', cache=0, cache_dir=None, count=50, data_format=None, dataset='imagenet_img', dataset_list=None, dataset_path='/home/pliu/opt/open-mmlab/data/imagenet', debug=False, find_peak_performance=False, inputs=['127.0.0.1:8080', '127.0.0.1:8083'], max_batchsize=32, max_latency=None, mlperf_conf='../../mlperf.conf', model='resnet18_8xb32_in1k', model_name='resnet50', output='/home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchserver-cpu-server-baseline', outputs=None, performance_sample_count=None, preprocessed_dir='/home/pliu/opt/open-mmlab/data/imagenet', profile='resnet50-pytorchserver', qps=None, samples_per_query=8, scenario='Server', threads=72, time=None, use_preprocessed_dataset=True, user_conf='user.conf')\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "['http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k', 'http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k']\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 751, 'pred_score': 0.25809788703918457, 'pred_class': 'racer, race car, racing car'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 858, 'pred_score': 0.1923191100358963, 'pred_class': 'tile roof'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 198, 'pred_score': 0.6867035627365112, 'pred_class': 'standard schnauzer'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 505, 'pred_score': 0.4000661075115204, 'pred_class': 'coffeepot'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 431, 'pred_score': 0.8852176070213318, 'pred_class': 'bassinet'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 230, 'pred_score': 0.9551196694374084, 'pred_class': 'Shetland sheepdog, Shetland sheep dog, Shetland'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 162, 'pred_score': 0.3623187839984894, 'pred_class': 'beagle'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 777, 'pred_score': 0.4723588228225708, 'pred_class': 'scabbard'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 327, 'pred_score': 0.5368857979774475, 'pred_class': 'starfish, sea star'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 256, 'pred_score': 0.9315462112426758, 'pred_class': 'Newfoundland, Newfoundland dog'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 846, 'pred_score': 0.29034459590911865, 'pred_class': 'table lamp'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 360, 'pred_score': 0.5157450437545776, 'pred_class': 'otter'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 21, 'pred_score': 0.6786596775054932, 'pred_class': 'kite'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 324, 'pred_score': 0.9946920275688171, 'pred_class': 'cabbage butterfly'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 674, 'pred_score': 0.5022905468940735, 'pred_class': 'mousetrap'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 370, 'pred_score': 0.9914773106575012, 'pred_class': 'guenon, guenon monkey'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 717, 'pred_score': 0.6099826693534851, 'pred_class': 'pickup, pickup truck'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 166, 'pred_score': 0.5676932334899902, 'pred_class': 'Walker hound, Walker foxhound'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 398, 'pred_score': 0.9103775024414062, 'pred_class': 'abacus'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 809, 'pred_score': 0.8774382472038269, 'pred_class': 'soup bowl'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 777, 'pred_score': 0.19426369667053223, 'pred_class': 'scabbard'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 586, 'pred_score': 0.9906468391418457, 'pred_class': 'half track'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 928, 'pred_score': 0.38588911294937134, 'pred_class': 'ice cream, icecream'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 517, 'pred_score': 0.8899758458137512, 'pred_class': 'crane'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 478, 'pred_score': 0.87732994556427, 'pred_class': 'carton'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 334, 'pred_score': 0.9879602193832397, 'pred_class': 'porcupine, hedgehog'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 948, 'pred_score': 0.99980229139328, 'pred_class': 'Granny Smith'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 23, 'pred_score': 0.9977461695671082, 'pred_class': 'vulture'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 727, 'pred_score': 0.9997475743293762, 'pred_class': 'planetarium'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 757, 'pred_score': 0.9892929792404175, 'pred_class': 'recreational vehicle, RV, R.V.'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 595, 'pred_score': 0.9752001166343689, 'pred_class': 'harvester, reaper'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 129, 'pred_score': 0.999009370803833, 'pred_class': 'spoonbill'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 26, 'pred_score': 0.8387568593025208, 'pred_class': 'common newt, Triturus vulgaris'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 887, 'pred_score': 0.9991544485092163, 'pred_class': 'vestment'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 172, 'pred_score': 0.26529407501220703, 'pred_class': 'whippet'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 520, 'pred_score': 0.3643844723701477, 'pred_class': 'crib, cot'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 283, 'pred_score': 0.43871352076530457, 'pred_class': 'Persian cat'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 58, 'pred_score': 0.381022185087204, 'pred_class': 'water snake'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 795, 'pred_score': 0.9730079174041748, 'pred_class': 'ski'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 756, 'pred_score': 0.8819327354431152, 'pred_class': 'rain barrel'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 270, 'pred_score': 0.99393230676651, 'pred_class': 'white wolf, Arctic wolf, Canis lupus tundrarum'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 491, 'pred_score': 0.1621904969215393, 'pred_class': 'chain saw, chainsaw'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 74, 'pred_score': 0.7773185968399048, 'pred_class': 'garden spider, Aranea diademata'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 565, 'pred_score': 0.9998120665550232, 'pred_class': 'freight car'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 55, 'pred_score': 0.40514686703681946, 'pred_class': 'green snake, grass snake'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 109, 'pred_score': 0.9904572367668152, 'pred_class': 'brain coral'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 147, 'pred_score': 0.9999884366989136, 'pred_class': 'grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 334, 'pred_score': 0.9866366982460022, 'pred_class': 'porcupine, hedgehog'}\n",
      "http://127.0.0.1:8083/predictions/resnet18_8xb32_in1k {'pred_label': 44, 'pred_score': 0.20575496554374695, 'pred_class': 'alligator lizard'}\n",
      "http://127.0.0.1:8080/predictions/resnet18_8xb32_in1k {'pred_label': 286, 'pred_score': 0.9992109537124634, 'pred_class': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "TestScenario.Server qps=0.06, mean=253.5499, time=831.849, acc=64.000%, queries=50, tiles=50.0:121.7394,80.0:523.5598,90.0:647.1271,95.0:715.1255,99.0:764.1697,99.9:776.5563\n"
     ]
    }
   ],
   "source": [
    "!python python/main.py \\\n",
    "    --profile resnet50-pytorchserver \\\n",
    "    --inputs 127.0.0.1:8080,127.0.0.1:8083 \\\n",
    "    --model resnet18_8xb32_in1k \\\n",
    "    --dataset-path /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --use_preprocessed_data \\\n",
    "    --preprocessed_dir /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --output /home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchserver-cpu-server-baseline \\\n",
    "    --scenario Server --accuracy --count 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:main:Namespace(accuracy=True, audit_conf='audit.config', backend='pytorch-server', cache=0, cache_dir=None, count=10, data_format=None, dataset='imagenet_img', dataset_list=None, dataset_path='/home/pliu/opt/open-mmlab/data/imagenet', debug=False, find_peak_performance=False, inputs=['127.0.0.1:8083'], max_batchsize=32, max_latency=None, mlperf_conf='../../mlperf.conf', model='mobilenet_v2', model_name='resnet50', output='/home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchserver-cpu-server-baseline', outputs=None, performance_sample_count=None, preprocessed_dir='/home/pliu/opt/open-mmlab/data/imagenet', profile='resnet50-pytorchserver', qps=1, samples_per_query=8, scenario='Server', threads=72, time=None, use_preprocessed_dataset=True, user_conf='user.conf')\n",
      "/home/pliu/opt/miniconda3/envs/mlperf/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "['http://127.0.0.1:8083/predictions/mobilenet_v2']\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'pred_label': 57, 'pred_score': 0.6789546012878418, 'pred_class': 'garter snake, grass snake'}\n",
      "57\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'pred_label': 34, 'pred_score': 0.6252733469009399, 'pred_class': 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea'}\n",
      "34\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'pred_label': 153, 'pred_score': 0.6973071694374084, 'pred_class': 'Maltese dog, Maltese terrier, Maltese'}\n",
      "153\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'pred_label': 809, 'pred_score': 0.5937680006027222, 'pred_class': 'soup bowl'}\n",
      "809\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'pred_label': 520, 'pred_score': 0.2600417137145996, 'pred_class': 'crib, cot'}\n",
      "520\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'pred_label': 674, 'pred_score': 0.8022262454032898, 'pred_class': 'mousetrap'}\n",
      "674\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'pred_label': 795, 'pred_score': 0.8007084727287292, 'pred_class': 'ski'}\n",
      "795\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'code': 500, 'type': 'InternalServerException', 'message': 'Worker died.'}\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000008.JPEG'], 'pred_label'\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'code': 500, 'type': 'InternalServerException', 'message': 'Worker died.'}\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000007.JPEG'], 'pred_label'\n",
      "http://127.0.0.1:8083/predictions/mobilenet_v2 {'code': 500, 'type': 'InternalServerException', 'message': 'Worker died.'}\n",
      "ERROR:main:thread: failed on contentid=['/home/pliu/opt/open-mmlab/data/imagenet/val/ILSVRC2012_val_00000003.JPEG'], 'pred_label'\n",
      "TestScenario.Server qps=0.06, mean=4.6521, time=126.326, acc=42.857%, queries=7, tiles=50.0:0.2674,80.0:0.3332,90.0:12.5976,95.0:21.7836,99.0:29.1324,99.9:30.7859\n"
     ]
    }
   ],
   "source": [
    "!python python/main.py \\\n",
    "    --profile resnet50-pytorchserver \\\n",
    "    --inputs 127.0.0.1:8083 \\\n",
    "    --model resnet18_8xb32_in1k \\\n",
    "    --dataset-path /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --use_preprocessed_data \\\n",
    "    --preprocessed_dir /home/pliu/opt/open-mmlab/data/imagenet \\\n",
    "    --output /home/pliu/opt/inference/vision/classification_and_detection/output/resnet50-pytorchserver-cpu-server-baseline \\\n",
    "    --scenario Server --accuracy --count 10 --qps 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
