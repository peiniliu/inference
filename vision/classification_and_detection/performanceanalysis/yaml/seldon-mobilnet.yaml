apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: online-inference
  namespace: scanflow-ai-pa
spec:
  name: online-inference
  predictors:
  - componentSpecs:
    - spec:
        initContainers:
        - name: tfserving-model-initializer
          resources:
            limits:
              cpu: 100m
              memory: 100Mi
            requests:
              cpu: 100m
              memory: 100Mi
        containers:
        - name: predictor-online
          resources:
            limits:
              cpu: '8'
              memory: 2Gi
            requests:
              cpu: '8'
              memory: 2Gi
        - name: tfserving
          resources:
            limits:
              cpu: '8'
              memory: 2Gi
            requests:
              cpu: '8'
              memory: 2Gi
    graph:
      endpoint:
        type: GRPC
      envSecretRefName: scanflow-secret
      implementation: TENSORFLOW_SERVER
      modelUri: s3://mlperf/mobilenet/tf/model
      name: predictor-online
      parameters:
      - name: model_name
        type: STRING
        value: predictor-online
      - name: model_input
        type: STRING
        value: input_7
      - name: model_output
        type: STRING
        value: predictions
      type: MODEL
    name: online-inference
    replicas: 1
    traffic: 100
